{
  "id": 108,
  "name": "blog/gravityui-aikit",
  "createdAt": "2026-01-27T13:57:57.515Z",
  "updatedAt": "2026-01-27T13:57:57.515Z",
  "type": "default",
  "isDeleted": false,
  "versionOnTranslationId": null,
  "searchCategorySlug": "blog",
  "regions": [],
  "pageId": 108,
  "regionCode": "en",
  "publishedVersionId": 268,
  "lastVersionId": 268,
  "content": "blocks:\n  - type: blog-header-block\n    resetPaddings: true\n    paddingBottom: l\n    width: m\n    verticalOffset: m\n    theme: dark\n    background:\n      image:\n        src: >-\n          https://storage.yandexcloud.net/gravity-landing-static/blog/blog-cover-bg.png\n        disableCompress: true\n      color: '#2A1A2A'\n      fullWidth: false\n  - type: blog-layout-block\n    resetPaddings: true\n    mobileOrder: reverse\n    children:\n      - type: blog-yfm-block\n        resetPaddings: true\n        column: right\n        text: >\n\n          ![image](https://storage.yandexcloud.net/gravity-landing-static/blog/aikit/speaker.jpg\n          =80x)\n\n\n          **Ilya Lomtev**\n\n          Frontend Developer\n      - type: blog-yfm-block\n        column: right\n        resetPaddings: true\n        text: |\n\n          In this article:\n\n            - [How and why we built AIKit](#why)\n            - [AIKit architecture: what we built on](#architecture)\n            - [How to build your own chat](#how)\n            - [How AIKit impacted services](#influence)\n            - [What’s next](#further)\n            - [How to try AIKit](#try)\n      - type: blog-yfm-block\n        column: left\n        resetPaddings: true\n        text: >\n\n          Over the past year, we’ve seen a boom in AI assistants, and it didn’t\n          bypass Yandex Cloud interfaces: sometimes a support chatbot with a\n          model would appear, sometimes an agent for operational tasks would\n          show up in the console. Teams connected models, designed dialog logic,\n          created UI, and assembled chats — each on their own.\n\n\n          Different teams built interfaces on the shared Gravity UI framework,\n          but over time so many variations appeared that it became hard to\n          maintain a consistent user experience. And colleagues increasingly ran\n          into the fact that they were spending time on the same solutions again\n          and again.\n\n\n          To stop reinventing the wheel every time, we consolidated our\n          accumulated practices into a single approach and built a tool for AI\n          chatbots —\n          [@gravity‑ui/aikit](https://github.com/gravity-ui/aikit){target=\"_blank\"}.\n          It lets you create a full-fledged assistant interface in a few days\n          and still easily adapt it to different scenarios.\n      - type: blog-media-block\n        column: left\n        resetPaddings: true\n        text: ''\n        image:\n          src: >-\n            https://storage.yandexcloud.net/gravity-landing-static/blog/aikit/pic0.png\n        fullscreen: true\n      - type: blog-yfm-block\n        column: left\n        resetPaddings: true\n        text: >\n\n          My name is Ilya Lomtev, I’m a Senior Developer on the Foundation\n          Services team at Yandex Cloud. In this article, I’ll explain why we\n          decided to build AIKit, how it works, share a bit about our future\n          plans — and what you can try on your side.\n      - type: blog-yfm-block\n        column: left\n        resetPaddings: true\n        text: >\n\n          ## How and why we built AIKit{#why}\n\n\n          Over the past year, the number of services with AI assistants in\n          Yandex Cloud has grown, for example: \n\n            * Code Assistant Chat in SourceCraft — the assistant helps developers write code, and in AI agent mode it creates and configures repositories, runs CI/CD processes, answers documentation questions, and automates tasks. It can also manage issues and pull requests, and work with code: explain it, create files, and edit files.\n\n            * An AI assistant in the cloud console — an assistant designed to manage resources in Yandex Cloud. Its main goal is to help configure, change, and manage cloud infrastructure quickly and safely, hiding the complexity of interacting with APIs and tools.\n\n          A dozen chats emerged in the ecosystem, each with its own logic,\n          message format, and set of corner cases. \n\n\n          We found that teams ended up with roughly the same set of tasks. What\n          most of them needed: \n\n            * neatly render user and assistant messages, \n\n            * properly organize response streaming, \n\n            * show an “assistant is typing” indicator, \n\n            * handle errors like dropped connections or retries. \n\n          The tasks are essentially the same, but there are many ways to solve\n          them — and the UX differs. For example, chat history placement and\n          display: it can be a separate screen that opens like a menu, or a list\n          of chats in a popup.\n\n\n          A problem became apparent: the experience across different chats\n          varied significantly. In some places the assistant streamed the\n          response, and in others it displayed a ready-made text at once. In one\n          interface messages were grouped, while in another they were shown as\n          one continuous feed. This broke the overall UX — users move between\n          products within the same ecosystem, but the assistant feels completely\n          different.   \n      - type: blog-media-block\n        column: left\n        resetPaddings: true\n        text: Examples of chats built with AIKit in the light theme\n        image:\n          src: >-\n            https://storage.yandexcloud.net/gravity-landing-static/blog/aikit/pic1.png\n        fullscreen: true\n      - type: blog-yfm-block\n        column: left\n        resetPaddings: true\n        text: >\n\n          It also became noticeable that rolling out new model features was\n          getting harder and harder. To communicate capabilities like tool use,\n          multimodality, or structured tool outputs to users, we had to align\n          the contract, update backends, and then update the UI in each team\n          separately. In such conditions, any changes took a lot of time and\n          didn’t scale well.\n\n\n          We wanted to stop this growth in variability and bring back\n          predictability. To do that, we needed to unify the data model and\n          working patterns, provide ready-made components and hooks so teams\n          wouldn’t have to start from scratch, and still leave room for\n          customization — because everyone’s scenarios are different. \n\n\n          That’s how we arrived at the idea of a standalone library,\n          @gravity‑ui/aikit — an extension of Gravity UI that follows the same\n          principles but is focused on modern AI scenarios: dialogs, assistants,\n          multimodality.\n      - type: blog-yfm-block\n        column: left\n        resetPaddings: true\n        text: \"\\n## AIKit architecture: what we built on{#architecture}\\n\\nWhen designing AIKit, we leaned on the experience of [AI\\_SDK](https://ai-sdk.dev/){target=\\\"_blank\\\"} and several fundamental principles.\\n\\n**Atomic Design at the core**: the whole library is built from atoms to pages. This structure provides a clear hierarchy, enables component reuse, and, when needed, lets you change behavior at any level.\\n\"\n      - type: blog-media-block\n        column: left\n        resetPaddings: true\n        text: ''\n        image:\n          src: >-\n            https://storage.yandexcloud.net/gravity-landing-static/blog/aikit/pic2.png\n        fullscreen: true\n      - type: blog-yfm-block\n        column: left\n        resetPaddings: true\n        text: >\n\n          **Completely SDK-agnostic**: AIKit doesn’t depend on any specific AI\n          provider. You can use OpenAI, Alice AI LLM, or your own backend — the\n          UI receives data through props, while state and requests remain on the\n          product side. \n\n\n          **Two levels of usage for complex scenarios**: there is a ready-made\n          component that works out of the box, and there is a hook with logic\n          that lets you fully control the UI. For example, you can use\n          `PromptInput` or build your own input based on `usePromptInput`. This\n          gives flexibility without having to rewrite the foundation.\n\n\n          **An extensible type system**. To ensure consistency and type safety,\n          we built an extensible data model. Messages are represented by a\n          single typed structure: there are user messages, assistant messages,\n          and several base content types — text (`text`), model reasoning\n          (`thinking`), tools (`tool`). At the same time, you can add your own\n          types via `MessageRendererRegistry`. \n\n\n          Everything is typed in TypeScript, which helps build complex scenarios\n          faster and avoid mistakes during development.\n\n\n          ```javascript\n\n          // 1. Define the data type\n\n          type ChartMessageContent = TMessageContent<\n              'chart',\n              {\n                  chartData: number[];\n                  chartType: 'bar' | 'line';\n              }\n          >;\n\n          // 2. Create the renderer component\n\n          const ChartRenderer = ({part}:\n          MessageContentComponentProps<ChartMessageContent>) => {\n              return <div>Chart visualization: {part.data.chartType}</div>;\n          };\n\n          // 3. Register the renderer\n\n          const customRegistry =\n          registerMessageRenderer(createMessageRendererRegistry(), 'chart', {\n              component: ChartRenderer,\n          });\n\n          // 4. Use it in AssistantMessage\n\n          <AssistantMessage message={message}\n          messageRendererRegistry={customRegistry} />;\n\n          ```\n\n\n          Finally, we provided theming via CSS variables, added i18n (RU/EN),\n          ensured accessibility (ARIA, keyboard navigation), and set up visual\n          regression tests using Playwright Component Testing in Docker — and\n          the library was ready for production use.\n\n\n          ### Under the hood \n\n\n          At the core of AIKit is a unified dialog model. To create it, we first\n          had to figure out the message hierarchy. \n\n\n          Messages themselves are fairly multifaceted entities. There’s the\n          first message from the LLM — that’s one stream. But within it there\n          can be many different nested messages: essentially reasoning,\n          suggestions, tool calls to solve a single question. All these\n          different sub-messages are, in fact, one message from the backend. But\n          each of them can also be a separate message in a simple LLM usage. \n\n\n          That’s why we kept the option to use the chat in both ways: messages\n          can be nested within each other, or they can be flat — it all depends\n          on your needs.\n\n\n          State management remains on the service side. AIKit doesn’t store data\n          itself — it receives it from outside. Teams can use React State,\n          Redux, Zustand, Reatom — whatever is convenient. We only provide hooks\n          that encapsulate typical UI logic, for example: \n\n            * smart scrolling with `useSmartScroll`;\n\n            * working with dates, e.g., locale-aware date formatting via `useDateFormatter`; \n\n            * handling tool messages via `useToolMessage`;\n\n            * and everything else you need to build a dialog.\n\n          On top of that, AIKit remains extensible. You can connect any models,\n          create your own content types, and build the UI entirely for your\n          tasks — leveraging logic from hooks or using ready-made components as\n          a base. The architecture allows experimentation without breaking\n          shared principles.\n      - type: blog-yfm-block\n        column: left\n        resetPaddings: true\n        text: >\n\n          ## How to build your own chat{#how}\n\n\n          To create your first chat, we’ll use the prepared ChatContainer\n          component:\n\n\n          ```javascript\n\n          import React, { useState } from 'react';\n\n          import { ChatContainer } from 'aikit';\n\n          import type { ChatType, MessageType } from 'aikit';\n\n\n          function App() {\n              const [messages, setMessages] = useState<MessageType[]>([]);\n              const [chats, setChats] = useState<ChatType[]>([]);\n              const [activeChat, setActiveChat] = useState<ChatType | null>(null);\n\n              const handleSendMessage = async (content: string) => {\n                  // Your message sending logic\n                  const response = await fetch('/api/chat', {\n                      method: 'POST',\n                      body: JSON.stringify({ message: content })\n                  });\n                  const data = await response.json();\n\n                  // Update state\n                  setMessages(prev => [...prev, data]);\n              };\n\n              return (\n            <ChatContainer\n              messages={[]}\n              onSendMessage={() => {}}\n              welcomeConfig={{\n                description: 'Start a conversation by typing a message or selecting a suggestion.',\n                image: <Icon data={() => {}} size={48}/>,\n                suggestionTitle: 'Try asking:',\n                suggestions: [\n                  {\n                    id: '1',\n                    title: 'Explain quantum computing in simple terms'\n                  },\n                  {\n                    id: '2',\n                    title: 'Write a poem about nature'\n                  },\n                  {\n                    id: '3',\n                    title: 'Help me debug my JavaScript code'\n                  },\n                  {\n                    id: '4',\n                    title: 'Summarize recent AI developments'\n                  }\n                ],\n                title: 'Welcome to AI Chat'\n              }}\n          />\n                  \n              );\n          }\n\n          ```\n\n\n          Out of the box, it looks like this:\n      - type: blog-media-block\n        column: left\n        resetPaddings: true\n        text: ''\n        image:\n          src: >-\n            https://storage.yandexcloud.net/gravity-landing-static/blog/aikit/pic3.png\n        fullscreen: true\n      - type: blog-yfm-block\n        column: left\n        resetPaddings: true\n        text: |\n\n          Let’s add a bit of holiday spirit: \n\n          1. Fix the initial state. \n\n              For finer tuning, we’ll assemble the chat from separate components: `Header`, `MessageList`, `PromptBox`.\n\n              ```javascript\n              import { Header, MessageList, PromptBox } from 'aikit';\n              function CustomChat() {\n                  return (\n                      <div className=\"custom-chat\">\n                          <Header title=\"AI Assistant\" onNewChat={() => {}} />\n                          <MessageList messages={messages} showTimestamp />\n                          <PromptBox onSend={handleSend} placeholder=\"Ask anything...\" />\n                      </div>\n                  );\n              }\n              ```\n\n          2. Apply different built-in message types imported via `MessageType`.\n\n              * `thinking` — will show the AI’s reasoning process (so users can explore the logic the assistant uses to prepare an answer).\n\n              * `tool` — works well for rendering interactive response blocks; in our case, it’s a code block with proper syntax highlighting and supported editing and clipboard copy operations.\n\n              You can also add your own types, for example, image messages:\n\n\n              ```javascript\n              type ImageMessage = BaseMessage<ImageMessageData> & { type: 'image' };\n\n\n              const ImageMessageView = ({ message }: { message: ImageMessage }) => (\n                  <div>\n                      <img src={message.data.imageUrl} />\n                      {message.data.caption && <p>{message.data.caption}</p>}\n                  </div>\n              );\n\n\n              const customTypes: MessageTypeRegistry = {\n                  image: {\n                      component: ImageMessageView,\n                      validator: (msg) => msg.type === 'image'\n                  }\n              };\n\n\n              <ChatContainer messages={messages} messageTypeRegistry={customTypes} />\n              ```\n\n          3. Add styling via CSS…\n\n              …and we’ll get a chat with Ded Moroz (Santa Claus):)\n      - type: blog-media-block\n        column: left\n        resetPaddings: true\n        text: ''\n        image:\n          src: >-\n            https://storage.yandexcloud.net/gravity-landing-static/blog/aikit/pic4.png\n        fullscreen: true\n      - type: blog-colored-text-block\n        column: left\n        resetPaddings: true\n        size: l\n        background:\n          color: '#CCD9FF'\n        text: >\n\n          For full customization of individual elements, you can use hooks —\n          we’d love to see your styling variations in the comments under the\n          article!\n      - type: blog-yfm-block\n        column: left\n        resetPaddings: true\n        text: >\n\n          ## How AIKit impacted services{#influence}\n\n\n          The result of using AIKit in Yandex Cloud became noticeable quickly.\n          In all services, assistants started behaving the same way: streaming\n          responses the same way, showing errors the same way, grouping messages\n          the same way. UX became consistent; now it’s easier to interact with\n          it across the entire ecosystem, and the behavior is more expected and\n          predictable.\n\n            * A unified UX language — assistant chats in different products now feel like part of one ecosystem. Users see predictable behavior: the same streaming, error handling, and interaction patterns. \n\n            * Much faster chat UI development. \n\n            * Centralized evolution — new features like the thinking content type or improved tool handling are added once and automatically become available to everyone. \n\n            * The library became the foundation for shaping AI interface standards in the ecosystem.\n      - type: blog-yfm-block\n        column: left\n        resetPaddings: true\n        text: >\n\n          ## What’s next{#further}\n\n\n          Now for the plans. We’ve identified several directions: \n\n            * Performance improvements via virtualization for working with very large chat histories. \n\n            * Expanding the core scenarios for new AI agent capabilities, which are actively developing. \n\n            * Adding utilities to simplify mapping data from popular AI models into our chat data model. \n\n          Additionally, we’ll continue improving the documentation and examples.\n          And of course, community growth — we want the library to be useful not\n          only inside the company, but also for external developers.\n      - type: blog-yfm-block\n        column: left\n        resetPaddings: true\n        text: >\n\n          ## How to try AIKit{#try}\n\n\n          Go to the [library\n          section](https://gravity-ui.com/libraries/aikit){target=\"_blank\"} on\n          our website. If you’re building your own AI assistant, want a fast and\n          predictable chat UI, and already use Gravity UI (or are ready to try\n          it), take a look at the README and examples. We’d also appreciate\n          feedback — open an issue, send a PR, and tell us what else you need\n          for your scenarios!\n\n\n          If you like our project, we’d appreciate a ⭐️ on\n          [AIKit](https://github.com/gravity-ui/aikit){target=\"_blank\"} and\n          [UIKit](https://github.com/gravity-ui/uikit){target=\"_blank\"}!\n  - type: blog-layout-block\n    resetPaddings: true\n    fullWidth: false\n    children:\n      - type: blog-meta-block\n        column: left\n        resetPaddings: true\n  - type: blog-suggest-block\n    resetPaddings: true\n",
  "title": "",
  "noIndex": false,
  "shareTitle": null,
  "shareDescription": null,
  "shareImage": "https://storage.yandexcloud.net/gravity-landing-static/blog/aikit/aikit-bg-cover.png",
  "pageLocaleId": null,
  "author": "timofeyevvv",
  "metaDescription": null,
  "keywords": [],
  "shareGenTitle": null,
  "canonicalLink": null,
  "sharingType": "custom",
  "sharingTheme": "light",
  "comment": "initial en",
  "shareImageUrl": "https://storage.yandexcloud.net/gravity-landing-static/blog/aikit/aikit-bg-cover.png",
  "pageRegionId": 117,
  "summary": null,
  "versionId": 268,
  "service": null,
  "solution": null,
  "locales": [
    {
      "id": 116,
      "pageId": 108,
      "locale": "ru",
      "createdAt": "2026-01-27T13:47:58.059Z",
      "updatedAt": "2026-01-27T13:47:58.118Z",
      "publishedVersionId": null,
      "lastVersionId": 263
    },
    {
      "id": 117,
      "pageId": 108,
      "locale": "en",
      "createdAt": "2026-01-27T13:47:58.121Z",
      "updatedAt": "2026-01-27T13:47:58.138Z",
      "publishedVersionId": null,
      "lastVersionId": 264
    }
  ],
  "pageRegions": [
    {
      "regionCode": "ru-ru",
      "publishedVersionId": null
    },
    {
      "regionCode": "en",
      "publishedVersionId": 268
    }
  ],
  "searchCategory": {
    "id": 7,
    "slug": "blog",
    "title": "Blog",
    "url": "/blog"
  },
  "voiceovers": []
}
{
    "id": 71,
    "name": "blog/graph",
    "createdAt": "2026-01-15T11:28:28.437Z",
    "updatedAt": "2026-01-15T11:28:28.437Z",
    "type": "default",
    "isDeleted": false,
    "versionOnTranslationId": null,
    "searchCategorySlug": "blog",
    "regions": [],
    "pageId": 71,
    "regionCode": "pt-br",
    "publishedVersionId": 199,
    "lastVersionId": 199,
    "content": "blocks:\n  - type: blog-header-block\n    resetPaddings: true\n    paddingBottom: l\n    width: m\n    verticalOffset: m\n    theme: dark\n    background:\n      image:\n        src: >-\n          https://storage.yandexcloud.net/gravity-landing-static/blog/blog-cover-bg.png\n        disableCompress: true\n      color: '#CCDAFF'\n      fullWidth: false\n  - type: blog-layout-block\n    resetPaddings: true\n    mobileOrder: reverse\n    children:\n      - type: blog-yfm-block\n        resetPaddings: true\n        column: right\n        text: >\n\n          ![image](https://storage.yandexcloud.net/gravity-landing-static/blog/canvas-vs-html/speaker.jpg\n          =80x)\n\n\n          **Андрей Щетинин**\n\n          Desenvolvedor sênior de interfaces\n      - type: blog-yfm-block\n        column: right\n        resetPaddings: true\n        text: |\n\n          Neste artigo:\n\n            - [De onde veio a demanda](#task)\n            - [Como chegamos à solução](#solution)\n            - [Personalização](#customization)\n            - [Nossa biblioteca de grafos: quais as vantagens e como usar](#library)\n            - [Existem alternativas?](#analogs)\n            - [Planos para o futuro](#future)\n            - [Experimente e junte-se a nós](#try)\n      - type: blog-yfm-block\n        column: left\n        resetPaddings: true\n        text: >\n\n          Olá! Meu nome é Andrey, sou desenvolvedor de interfaces na equipe de\n          User Experience de serviços de infraestrutura do Yandex. Desenvolvemos o Gravity UI\n          — uma design system open source e uma biblioteca de componentes React, usada por\n          dezenas de produtos dentro e fora da empresa.\n          Hoje vou contar como nos deparamos com a tarefa de visualizar grafos complexos,\n          por que as soluções existentes não nos atenderam e como, no fim,\n          surgiu o @gravity‑ui/graph — uma biblioteca que decidimos abrir\n          para a comunidade.\n\n\n          Esta história começou com um problema prático: precisávamos renderizar\n          grafos com 10.000+ elementos e componentes interativos. No Yandex há\n          muitos projetos em que os usuários criam pipelines complexos de processamento\n          de dados — de processos ETL simples até machine learning. Quando esses\n          pipelines são criados programaticamente, a quantidade de blocos pode chegar\n          a dezenas de milhares.\n\n\n          As soluções existentes não nos atendiam:\n\n            * **Bibliotecas HTML/SVG** têm boa aparência e são convenientes no desenvolvimento, mas começam a travar já com centenas de elementos.\n            * **Soluções em Canvas** dão conta da performance, mas exigem uma quantidade enorme de código para criar elementos de UI complexos.\n\n          Desenhar um botão com cantos arredondados e gradiente em Canvas\n          não é difícil. Porém, os problemas aparecem quando é preciso criar controles\n          complexos próprios ou uma marcação/layout — será necessário escrever dezenas de linhas\n          de comandos de desenho de baixo nível. Cada elemento de interface precisa\n          ser programado do zero — do tratamento de cliques às animações. E nós precisávamos\n          de componentes de UI completos: botões, selects, campos de entrada,\n          drag‑and‑drop.\n\n\n          Decidimos não escolher entre Canvas e HTML, e sim usar o melhor\n          de ambas as tecnologias. A ideia era simples: alternar automaticamente\n          entre os modos dependendo do quão perto o usuário está\n          visualizando o grafo.\n      - type: blog-media-block\n        column: left\n        resetPaddings: true\n        paddingBottom: s\n        text: ''\n        image:\n          src: >-\n            https://storage.yandexcloud.net/gravity-landing-static/blog/canvas-vs-html/pic1.png\n        fullscreen: true\n      - type: blog-yfm-block\n        column: left\n        resetPaddings: true\n        text: |\n\n          #### Experimente você mesmo\n\n            * [Repositório no GitHub](https://github.com/gravity-ui/graph){target=\"_blank\"}\n            * [Storybook com exemplos](https://preview.gravity-ui.com/graph/){target=\"_blank\"}\n            * [Playground](https://gravity-ui.com/ru/libraries/graph/playground){target=\"_blank\"}\n      - type: blog-yfm-block\n        column: left\n        resetPaddings: true\n        text: >\n\n          ## De onde veio a demanda{#task}\n\n\n          ### Nirvana e seus grafos\n\n\n          No Yandex temos o serviço Nirvana para criar e executar grafos\n          de processamento de dados (nós\n          [escrevemos](https://habr.com/ru/companies/yandex/articles/351016/){target=\"_blank\"}\n          sobre ele lá em 2018). O serviço é grande, popular e existe há muito tempo.\n\n\n          Parte dos usuários cria grafos manualmente — usam o mouse, adicionam\n          blocos, conectam nós. Com esses grafos não há problemas: não há muitos blocos e\n          tudo funciona muito bem. Mas há projetos que criam grafos\n          programaticamente. E aí começam as dificuldades: eles podem colocar em um\n          único grafo até 10.000 operações. E fica assim:\n      - type: blog-media-block\n        column: left\n        resetPaddings: true\n        text: ''\n        image:\n          src: >-\n            https://storage.yandexcloud.net/gravity-landing-static/blog/canvas-vs-html/pic2.png\n        fullscreen: true\n      - type: blog-yfm-block\n        column: left\n        resetPaddings: true\n        text: >\n\n          {% cut \"E assim:\" %}\n\n\n          ![image](https://storage.yandexcloud.net/gravity-landing-static/blog/canvas-vs-html/pic2-1.png\n          =830x)\n\n          ![image](https://storage.yandexcloud.net/gravity-landing-static/blog/canvas-vs-html/pic2-2.png\n          =830x)\n\n          ![image](https://storage.yandexcloud.net/gravity-landing-static/blog/canvas-vs-html/pic2-3.png\n          =830x)\n\n          ![image](https://storage.yandexcloud.net/gravity-landing-static/blog/canvas-vs-html/pic2-4.png\n          =830x)\n\n          ![image](https://storage.yandexcloud.net/gravity-landing-static/blog/canvas-vs-html/pic2-5.png\n          =830x)\n\n\n          {% endcut %}\n\n\n          Grafos assim, uma combinação comum de HTML + SVG simplesmente não aguenta.\n          O navegador começa a travar, a memória vaza, o usuário sofre. Tentamos\n          resolver o problema de forma direta: otimizar a renderização de HTML, mas cedo ou\n          tarde esbarrávamos em limites físicos — o DOM simplesmente não foi pensado para\n          milhares de elementos interativos flutuantes visíveis ao mesmo tempo.\n\n\n          Precisávamos de outra solução, e no navegador só nos restava o Canvas. Só\n          ele pode garantir a performance necessária.\n\n\n          A primeira ideia foi encontrar uma solução pronta. Era 2017–2018, e nós\n          revisamos as bibliotecas populares para Canvas ou renderização de grafos,\n          mas todas esbarravam no mesmo problema: ou você usa\n          Canvas e elementos primitivos, ou usa HTML/SVG e sacrifica\n          a performance.\n\n\n          E se não escolhermos?\n\n\n          ### Level of Details: inspiração do GameDev\n\n\n          No GameDev e na cartografia existe um conceito muito bom — Level of Details\n          (LOD). Essa técnica nasceu de uma necessidade — como mostrar um mundo enorme\n          sem matar a performance?\n\n\n          A ideia é simples: um mesmo objeto pode ter vários níveis de\n          detalhamento dependendo de quão perto ele é observado. Em jogos,\n          isso é especialmente visível:\n\n            * Ao longe, você vê montanhas — polígonos simples com textura básica.\n            * Ao se aproximar — surgem detalhes: grama, pedras, sombras.\n            * Mais perto ainda — dá para ver folhas individuais nas árvores.\n\n          Ninguém renderiza milhões de polígonos de grama quando o jogador está no\n          topo da montanha olhando para longe.\n\n\n          Em mapas, o princípio é o mesmo — cada nível de zoom tem seu conjunto de dados\n          e seu nível de detalhamento:\n\n            * Zoom de continente — aparecem apenas países.\n            * Aproximando da cidade — surgem ruas e bairros.\n            * Mais perto — números de casas, cafés, pontos de ônibus.\n\n          Entendemos: o usuário não precisa de botões interativos em um zoom amplo\n          de um grafo com 10.000 blocos — ele nem vai vê-los, nem conseguirá\n          trabalhar com eles.\n\n\n          Mais ainda, tentar renderizar 10.000 elementos HTML simultaneamente\n          vai congelar o navegador. Mas quando o usuário dá zoom em uma área específica,\n          a quantidade de blocos visíveis cai drasticamente — de 10.000 para, digamos, 50. É\n          aí que sobram recursos para componentes HTML com rica\n          interatividade.\n\n\n          ### Três níveis do nosso esquema Level of Details\n\n\n          #### Minimalistic (escala 0,1–0,3) — Canvas com primitivos simples\n\n\n          Nesse modo, o usuário vê a arquitetura geral do sistema: onde\n          ficam os principais grupos de blocos e como eles se conectam.\n          Cada bloco é um retângulo simples com codificação básica por cores.\n          Sem textos, botões ou ícones detalhados. Em compensação, é possível\n          renderizar confortavelmente milhares de elementos. Nesse nível, o usuário escolhe\n          uma área para estudar em detalhe.\n      - type: blog-media-block\n        column: left\n        resetPaddings: true\n        paddingBottom: s\n        text: ''\n        image:\n          src: >-\n            https://storage.yandexcloud.net/gravity-landing-static/blog/canvas-vs-html/pic3.png\n        fullscreen: true\n      - type: blog-yfm-block\n        column: left\n        resetPaddings: true\n        text: >\n\n          #### Schematic (escala 0,3–0,7) — Canvas com detalhes\n\n\n          Surgem os nomes dos blocos, ícones de estado e âncoras para conexões.\n          O texto é renderizado via Canvas API — é rápido, mas as possibilidades\n          de estilização são limitadas. As ligações entre os blocos ficam mais\n          informativas: dá para mostrar direção do fluxo de dados, status\n          da conexão. É um modo de transição, no qual a performance do Canvas\n          se combina com uma informatividade básica.\n      - type: blog-media-block\n        column: left\n        resetPaddings: true\n        paddingBottom: s\n        text: ''\n        image:\n          src: >-\n            https://storage.yandexcloud.net/gravity-landing-static/blog/canvas-vs-html/pic4.png\n        fullscreen: true\n      - type: blog-yfm-block\n        column: left\n        resetPaddings: true\n        text: >\n\n          #### Detailed (escala 0,7+) — HTML com interatividade completa\n\n\n          Aqui os blocos se transformam em componentes de interface completos: com\n          botões de controle, campos de parâmetros, barras de progresso,\n          selects. Dá para usar quaisquer recursos de HTML/CSS e conectar\n          bibliotecas de UI. Nesse modo, normalmente cabem no viewport não mais que\n          20–50 blocos, o que é confortável para trabalho detalhado.\n      - type: blog-media-block\n        column: left\n        resetPaddings: true\n        text: ''\n        image:\n          src: >-\n            https://storage.yandexcloud.net/gravity-landing-static/blog/canvas-vs-html/pic5.png\n        fullscreen: true\n      - type: blog-yfm-block\n        column: left\n        resetPaddings: true\n        text: >\n\n          **E se calcularmos o FPS para escolher o nível de detalhamento?**\n\n\n          Tivemos abordagens para escolher a detalhação com base no FPS. Mas descobrimos que\n          essa abordagem cria instabilidade — quando a performance cresce,\n          o sistema muda para um modo mais detalhado, o que reduz o FPS e\n          pode provocar a troca de volta — e assim por diante.\n      - type: blog-yfm-block\n        column: left\n        resetPaddings: true\n        text: >\n\n          ## Como chegamos à solução{#solution}\n\n\n          Ok, LOD é ótimo. Mas a implementação exige Canvas por causa da\n          performance, e isso traz uma nova dor de cabeça. Desenhar no Canvas\n          não é tão difícil — os problemas aparecem quando precisamos fazer\n          interatividade.\n\n\n          ### Problema: como entender onde o usuário clicou?\n\n\n          Em HTML, tudo é simples: clicou no botão — o evento chega diretamente\n          ao elemento. No Canvas é mais complicado: clicou no canvas — e daí? Precisamos\n          descobrir por conta própria em qual elemento o usuário clicou.\n\n\n          Basicamente existem três abordagens:\n\n            * Pixel Testing (color picking),\n            * Geometric approach (varredura simples de todos os elementos),\n            * Spatial Indexing (índice espacial).\n\n          #### Pixel Testing (color picking)\n\n\n          A ideia é simples: criamos um segundo canvas invisível, copiamos a cena para lá, mas\n          pintamos cada elemento com uma cor única, que será tratada como o ID\n          do objeto. Ao clicar, lemos a cor do pixel sob o cursor do mouse via\n          getImageData e assim obtemos o ID do elemento.\n\n\n          #|\n\n          ||**Prós**|**Contras**||\n\n          ||* Implementa-se em algumas dezenas de linhas\n\n\n          * Não exige estruturas de dados adicionais|* O anti-aliasing do Canvas\n          mistura cores — um clique na borda da forma pode retornar um ID “inválido”\n\n\n          * Desativar anti‑aliasing em 2D‑Canvas não é possível\n\n\n          * O segundo canvas duplica a memória e dobra o passe de renderização||\n\n          |#\n\n\n          Para cenas pequenas, o método serve, mas com 10.000+ elementos a taxa\n          de erros se torna inaceitável — deixamos o Pixel Testing de lado.\n\n\n          #### Geometric approach (varredura simples de todos os elementos)\n\n\n          A ideia é simples: percorremos todos os elementos e verificamos se o ponto\n          do clique está dentro do elemento.\n\n\n          #|\n\n          ||**Prós**|**Contras**||\n\n          ||* Implementa-se em algumas dezenas de linhas\n\n\n          * Não exige estruturas de dados adicionais|* Funciona muito lentamente\n          com um grande número de elementos\n\n\n          * Não serve para cenas grandes||\n\n          |#\n\n\n          #### Spatial Indexing\n\n\n          Uma evolução da abordagem geométrica. Na abordagem geométrica, nós\n          esbarrávamos na quantidade de elementos. Algoritmos de índice espacial\n          tentam agrupar elementos próximos, usando principalmente árvores, o que\n          permite reduzir a complexidade para log n.\n\n\n          Existem muitos algoritmos de índice espacial; escolhemos\n          a estrutura de dados R‑Tree na forma da biblioteca\n          [rbush](https://github.com/mourner/rbush){target=\"_blank\"}.\n\n\n          R‑Tree — como o nome sugere, é uma árvore em que cada objeto\n          é colocado dentro de um retângulo de tamanho mínimo (MBR), e então esses\n          retângulos são agrupados em retângulos maiores. Assim\n          forma-se uma árvore em que cada retângulo contém outros\n          retângulos.\n      - type: blog-media-block\n        column: left\n        resetPaddings: true\n        text: >-\n          Imagem da Wikipédia\n          [R‑tree](https://en.wikipedia.org/wiki/R-tree){target=\"_blank\"}\n        image:\n          src: >-\n            https://storage.yandexcloud.net/gravity-landing-static/blog/canvas-vs-html/pic6.png\n        fullscreen: true\n      - type: blog-yfm-block\n        column: left\n        resetPaddings: true\n        text: >\n\n          Para buscar no RTree, precisamos descer pela árvore (para dentro\n          do retângulo) até chegar ao elemento específico. O caminho\n          é escolhido verificando a interseção do retângulo de busca com o MBR. Todos\n          os ramos cujas bounding boxes nem tocam o retângulo de busca\n          são descartados imediatamente — por isso a profundidade do percurso normalmente\n          se limita a 3–5 níveis, e a própria busca leva microssegundos mesmo com\n          dezenas de milhares de elementos.\n\n\n          Essa opção funciona, embora seja mais lenta (O(log n) no melhor caso e\n          O(n) no pior) do que o pixel testing, mas é mais precisa e exige\n          menos memória.\n\n\n          #### Modelo de eventos\n\n\n          Com base no RTree, agora podemos construir nosso modelo de eventos.\n          Quando o usuário clica, inicia-se um hit-test: formamos\n          um retângulo de 1×1 pixel nas coordenadas do cursor e buscamos sua\n          interseção no R‑Tree. Ao obter o elemento em que esse\n          retângulo cai, delegamos o evento a esse elemento. Se o elemento não\n          interromper o evento, então o evento é passado ao seu pai e assim até\n          a raiz. O comportamento desse modelo se parece com o comportamento do\n          modelo de eventos do navegador ao qual estamos acostumados. Os eventos podem\n          ser interceptados, prevenidos ou ter a propagação interrompida.\n\n\n          Como mencionei, no hit-test formamos um retângulo de\n          1×1 pixel, o que significa que podemos formar um retângulo\n          de qualquer tamanho. E isso vai nos ajudar a fazer mais uma\n          otimização muito importante — Spatial Culling.\n\n\n          ### Spatial Culling\n\n\n          Spatial Culling é uma técnica de otimização de renderização, voltada\n          a não desenhar o que não é visível. Por exemplo, para não desenhar\n          objetos que estão fora do espaço da câmera ou que estão\n          bloqueados por outros elementos da cena. Como nosso grafo é desenhado em\n          2D, basta não desenhar apenas os objetos\n          que estão fora da área visível da câmera (viewport).\n\n\n          Como funciona:\n\n            * a cada movimento ou zoom da câmera, formamos um retângulo igual ao viewport atual;\n            * buscamos sua interseção no R‑Tree;\n            * o resultado é uma lista de elementos que realmente estão visíveis;\n            * renderizamos apenas eles; todo o resto é ignorado.\n\n          Esse truque torna a performance quase independente do número total\n          de elementos: se couberem 40 blocos no frame, a biblioteca\n          desenhará exatamente 40, e não dezenas de milhares escondidos\n          fora da tela. Em escalas distantes, um grande número de elementos cai no viewport,\n          então desenhamos primitivos leves em Canvas; ao aproximar a câmera,\n          a quantidade de elementos diminui e os recursos liberados permitem\n          mudar para o modo HTML com detalhamento completo.\n\n\n          Juntando tudo, fica um esquema simples:\n\n            * Canvas é responsável pela velocidade,\n            * HTML — pela interatividade,\n            * R‑Tree e Spatial Culling combinam tudo discretamente em um sistema único, permitindo entender rapidamente quais elementos podem ser desenhados na camada HTML.\n\n          Enquanto a câmera se move, um viewport pequeno pede ao R‑Tree apenas\n          os objetos que realmente estão no frame. Essa abordagem nos permite\n          desenhar grafos realmente grandes, ou pelo menos ter uma reserva\n          de performance até que o usuário restrinja\n          o viewport.\n\n\n          No fim, no núcleo a biblioteca contém:\n\n            * modo Canvas com primitivos simples;\n            * modo HTML com detalhamento completo;\n            * R‑Tree e Spatial Culling para otimização de performance;\n            * um modelo de eventos familiar.\n\n          Mas para produção isso não é suficiente; é preciso ter a capacidade de\n          estender a biblioteca e customizá-la para as suas necessidades.\n      - type: blog-yfm-block\n        column: left\n        resetPaddings: true\n        text: >\n\n          ## Personalização{#customization}\n\n\n          A biblioteca oferece duas formas complementares de extensão e\n          alteração de comportamento:\n\n            * Sobrescrever componentes base. Alteramos a lógica de Block, Anchor, Connection padrão.\n            * Estender via camadas (Layers). Adicionamos funcionalidades essencialmente novas acima/abaixo da cena existente.\n\n          ### Sobrescrever componentes\n\n\n          Quando é preciso modificar a aparência ou o comportamento de elementos\n          já existentes, herdamos da classe base e sobrescrevemos os métodos\n          principais. Depois, registramos o componente com um nome próprio.\n\n\n          #### Customização de blocos\n\n\n          Por exemplo, se você precisa criar um grafo com barras de progresso nos blocos —\n          digamos, para mostrar o status de execução de tarefas em um pipeline — você\n          pode customizar facilmente os blocos padrão:\n\n\n          ```json\n\n          import { CanvasBlock } from \"@gravity‑ui/graph\";\n\n\n          class ProgressBlock extends CanvasBlock {\n            // Forma base do bloco com cantos arredondados\n            public override renderBody(ctx: CanvasRenderingContext2D): void {\n              ctx.fillStyle = \"#ddd\";\n              ctx.beginPath();\n              ctx.roundRect(this.state.x, this.state.y, this.state.width, this.state.height, 12);\n              ctx.fill();\n              ctx.closePath();\n            }\n\n            public renderSchematicView(ctx: CanvasRenderingContext2D): void {\n              const progress = this.state.meta?.progress || 0;\n\n              // Desenhamos a base do bloco\n              this.renderBody(ctx);\n\n              // Barra de progresso com indicação por cores\n              const progressWidth = (this.state.width - 20) * (progress / 100);\n              ctx.fillStyle = progress < 50 ? \"#ff6b6b\" : progress < 80 ? \"#feca57\" : \"#48cae4\";\n              ctx.fillRect(this.state.x + 10, this.state.y + this.state.height - 15, progressWidth, 8);\n\n              // Borda da barra de progresso\n              ctx.strokeStyle = \"#ddd\";\n              ctx.lineWidth = 1;\n              ctx.strokeRect(this.state.x + 10, this.state.y + this.state.height - 15, this.state.width - 20, 8);\n\n              // Texto com percentuais e nome\n              ctx.fillStyle = \"#2d3436\";\n              ctx.font = \"12px Arial\";\n              ctx.textAlign = \"center\";\n              ctx.fillText(`${Math.round(progress)}%`, this.state.x + this.state.width / 2, this.state.y + 20);\n              ctx.fillText(this.state.name, this.state.x + this.state.width / 2, this.state.y + 40);\n            }\n          }\n\n          ```\n\n\n          #### Customização de conexões\n\n\n          Da mesma forma, se você precisa mudar o comportamento e a aparência das ligações —\n          por exemplo, mostrar a intensidade do fluxo de dados entre blocos — você\n          pode criar uma conexão customizada:\n\n\n          ```json\n\n          import { BlockConnection } from \"@gravity-ui/graph\";\n\n\n          class DataFlowConnection extends BlockConnection {\n            public override style(ctx: CanvasRenderingContext2D) {\n              // Obtemos dados do fluxo a partir dos blocos conectados\n              const sourceBlock = this.sourceBlock;\n              const targetBlock = this.targetBlock;\n\n              const sourceProgress = sourceBlock?.state.meta?.progress || 0;\n              const targetProgress = targetBlock?.state.meta?.progress || 0;\n\n              // Calculamos a intensidade do fluxo com base no progresso dos blocos\n              const flowRate = Math.min(sourceProgress, targetProgress);\n              const isActive = flowRate > 10; // Fluxo está ativo quando o progresso > 10%\n\n              if (isActive) {\n                // Fluxo ativo -- linha verde grossa\n                ctx.strokeStyle = \"#00b894\";\n                ctx.lineWidth = Math.max(2, Math.min(6, flowRate / 20));\n              } else {\n                // Fluxo inativo -- linha cinza tracejada\n                ctx.strokeStyle = \"#ddd\";\n                ctx.lineWidth = this.context.camera.getCameraScale();\n                ctx.setLineDash([5, 5]);\n              }\n\n              return { type: \"stroke\" };\n            }\n          }\n\n          ```\n\n\n          #### Uso de componentes customizados\n\n\n          Registramos os componentes criados nas configurações do grafo:\n\n\n          ```json\n\n          const customGraph = new Graph({\n            blocks: [\n              {\n                id: \"task1\",\n                is: \"progress\",\n                x: 100,\n                y: 100,\n                width: 200,\n                height: 80,\n                name: \"Data Processing\",\n                meta: { progress: 75 },\n              },\n              {\n                id: \"task2\",\n                is: \"progress\",\n                x: 400,\n                y: 100,\n                width: 200,\n                height: 80,\n                name: \"Analysis\",\n                meta: { progress: 30 },\n              },\n              {\n                id: \"task3\",\n                is: \"progress\",\n                x: 700,\n                y: 100,\n                width: 200,\n                height: 80,\n                name: \"Output\",\n                meta: { progress: 5 },\n              },\n            ],\n            connections: [\n              { sourceBlockId: \"task1\", targetBlockId: \"task2\" },\n              { sourceBlockId: \"task2\", targetBlockId: \"task3\" },\n            ],\n            settings: {\n              // Registramos os blocos customizados\n              blockComponents: {\n                'progress': ProgressBlock,\n              },\n              // Registramos a conexão customizada para todas as ligações\n              connection: DataFlowConnection,\n              useBezierConnections: true,\n            },\n          });\n\n\n          customGraph.setEntities({\n            blocks: [\n              {\n              is: 'progress',\n              id: '1',\n              name: \"progress block',\n              x: 10, \n              y: 10, \n              width: 10, \n              height: 10,\n              anchors: [],\n              selected: false,\n              }\n            ]\n          })\n\n\n          customGraph.start();\n\n          ```\n\n\n          #### Resultado\n\n\n          No resultado, obtemos um grafo em que:\n\n            * os blocos mostram o progresso atual com indicação por cores;\n            * as conexões visualizam o fluxo de dados: fluxos ativos — verdes e grossos; inativos — cinzas e tracejados;\n            * ao dar zoom, os blocos alternam automaticamente para o modo HTML com interatividade completa.\n\n          ### Extensão via camadas\n\n\n          Camadas são elementos Canvas ou HTML adicionais que\n          são inseridos no “espaço” do grafo. Na prática, cada camada é um\n          canal de renderização separado, que pode conter seu próprio canvas\n          para gráficos rápidos ou um container HTML para elementos interativos\n          complexos.\n\n\n          Aliás, é exatamente via camadas que funciona a integração React da nossa biblioteca:\n          componentes React são renderizados na camada HTML via React Portal.\n\n\n          #### Arquitetura de camadas\n\n\n          Camadas são mais uma solução-chave para o dilema Canvas vs HTML.\n          Elas sincronizam as posições dos elementos Canvas e HTML, garantindo\n          sua sobreposição correta. Isso permite alternar\n          Canvas e HTML sem rupturas, permanecendo em um único espaço. O grafo\n          consiste em camadas independentes sobrepostas umas às outras:\n      - type: blog-media-block\n        column: left\n        resetPaddings: true\n        text: ''\n        image:\n          src: >-\n            https://storage.yandexcloud.net/gravity-landing-static/blog/canvas-vs-html/pic7.png\n        fullscreen: true\n      - type: blog-yfm-block\n        column: left\n        resetPaddings: true\n        text: >\n\n          As camadas podem trabalhar em dois sistemas de coordenadas:\n\n            * Vinculadas ao grafo (`transformByCameraPosition: true`):\n\n              * elementos se movem junto com a câmera,\n              * blocos, conexões, elementos do grafo.\n\n            * Fixas na tela (`transformByCameraPosition: false`):\n\n              * permanecem no lugar ao panoramizar,\n              * toolbars, legendas, controles de UI.\n\n          #### Como funciona a integração React\n\n\n          A camada com integração React é bem ilustrativa para demonstrar o que\n          são camadas. Primeiro, vamos olhar para um componente que destaca\n          a lista de blocos que estão na área visível da câmera. Para isso,\n          precisamos assinar mudanças da câmera e, após cada mudança,\n          checar a interseção do viewport da câmera com o hitbox dos elementos.\n\n\n          ```json\n\n          import { Graph } from \"@gravity-ui/graph\";\n\n\n          const BlocksList = ({ graph, renderBlock }: { graph: Graph,\n          renderBlock: (graph: Graph, block: TBlock) => React.JSX.Element }) =>\n          {\n            const [blocks, setBlocks] = useState([]);\n\n            const updateVisibleList = useCallback(() => {\n              const cameraState = graph.cameraService.getCameraState();\n              const CAMERA_VIEWPORT_TRESHOLD = 0.5;\n              const x = -cameraState.relativeX - cameraState.relativeWidth * CAMERA_VIEWPORT_TRESHOLD;\n              const y = -cameraState.relativeY - cameraState.relativeHeight * CAMERA_VIEWPORT_TRESHOLD;\n              const width = -cameraState.relativeX + cameraState.relativeWidth * (1 + CAMERA_VIEWPORT_TRESHOLD) - x;\n              const height = -cameraState.relativeY + cameraState.relativeHeight * (1 + CAMERA_VIEWPORT_TRESHOLD) - y;\n              \n              const blocks = graph\n                .getElementsOverRect(\n                  {\n                    x,\n                    y,\n                    width,\n                    height,\n                  }, // define a área na qual a lista de blocos será buscada\n                  [CanvasBlock] // define os tipos de elementos que serão buscados na área visível da câmera\n                ).map((component) => component.connectedState); // Obtemos a lista de modelos de blocos\n\n                setBlocks(blocks);\n            });\n\n              useGraphEvent(graph, \"camera-change\", ({ scale }) => {\n                if (scale >= 0.7) {\n                  // Se a escala for maior que 0.7, atualizamos a lista de blocos\n                  updateVisibleList()\n                  return;\n                }\n                setBlocks([]);\n              });\n\n              return blocks.map(block => <React.Fragment key={block.id}>{renderBlock(graphObject, block)}</React.Fragment>)\n          }\n\n          ```\n\n\n          Agora vamos ver a descrição da própria camada, que\n          usará esse componente.\n\n\n          ```json\n\n          import { Layer } from '@gravity-ui/graph';\n\n\n          class ReactLayer extends Layer {\n            constructor(props: TReactLayerProps) {\n              super({\n                html: {\n                  zIndex: 3, // elevamos a camada acima das demais\n                  classNames: [\"no-user-select\"], // adicionamos uma classe para desativar seleção de texto\n                  transformByCameraPosition: true, // camada vinculada à câmera — agora ela se moverá junto com a câmera\n                },\n                ...props,\n              });\n            }\n\n            public renderPortal(renderBlock: <T extends TBlock>(block: T) => React.JSX.Element) {\n              if (!this.getHTML()) {\n                return null;\n              }\n\n              const htmlLayer = this.getHTML() as HTMLDivElement;\n\n              return createPortal(\n                React.createElement(BlocksList, {\n                  graph: this.context.graph,\n                  renderBlock: renderBlock,\n                }),\n                htmlLayer,\n              );\n            }\n          }\n\n          ```\n\n\n          Agora podemos usar essa camada na nossa aplicação.\n\n\n          ```json\n\n          import { Flex } from \"@gravity-ui/uikit\";\n\n\n          const graph = useMemo(() => new Graph());\n\n          const containerRef = useRef<HTMLDivElement>();\n\n\n          useEffect(() => {\n              if (containerRef.current) {\n                graph.attach(containerRef.current);\n              }\n\n              return () => {\n                graph.detach();\n              };\n            }, [graph, containerRef]);\n\n\n          const reactLayer = useLayer(graph, ReactLayer, {});\n\n\n          const renderBlock = useCallback((graph, block) => <Block graph={graph}\n          block={block}>{block.name}</Block>)\n\n            return (\n              <div>\n                <div style={{ position: \"absolute\", overflow: \"hidden\", width: \"100%\", height: \"100%\" }} ref={containerRef}>\n                  {graph && reactLayer && reactLayer.renderPortal(renderBlock)}\n                </div>\n              </div>\n            );\n          ```\n      - type: blog-yfm-block\n        column: left\n        resetPaddings: true\n        text: >\n\n          No geral, é tudo bem simples. Nada do que foi descrito acima\n          precisa ser escrito por você — já está tudo implementado e pronto para uso.\n      - type: blog-yfm-block\n        column: left\n        resetPaddings: true\n        text: >\n\n          ## Nossa biblioteca de grafos: quais as vantagens e como usar{#library}\n\n\n          Quando começamos a trabalhar na biblioteca, a questão principal era: como\n          fazer com que o desenvolvedor não precisasse escolher entre\n          performance e conveniência de desenvolvimento? A resposta acabou sendo\n          automatizar essa escolha.\n\n\n          ### Vantagens\n\n\n          #### Performance + conveniência\n\n\n          [@gravity‑ui/graph](https://github.com/gravity-ui/graph){target=\"_blank\"}\n          alterna automaticamente entre Canvas e HTML dependendo da\n          escala. Isso significa que você obtém:\n\n            * 60 FPS estáveis em grafos com milhares de elementos.\n            * A possibilidade de usar componentes HTML completos com rica interatividade na visualização detalhada.\n            * Um modelo de eventos único independentemente do método de renderização — click, mouseenter funcionam da mesma forma no Canvas e no HTML.\n\n          #### Compatibilidade com bibliotecas de UI\n\n\n          Uma das principais vantagens é a compatibilidade com quaisquer bibliotecas de UI.\n          Se sua equipe usa:\n\n            * Gravity UI,\n            * Material‑UI,\n            * Ant Design,\n            * componentes customizados.\n\n          … então você não precisa abrir mão delas! Ao aumentar a escala, o grafo\n          alterna automaticamente para o modo HTML, onde `Button`,\n          `Select`, `DatePicker` no tema de cores desejado funcionam exatamente\n          como em uma aplicação React comum.\n\n\n          #### Framework agnostic\n\n\n          Embora tenhamos implementado o renderer HTML base usando React,\n          tentamos desenvolver a biblioteca de modo que ela permaneça\n          framework‑agnostic. Isso significa que, se necessário, você pode\n          implementar com relativa facilidade uma camada de integração com\n          o seu framework favorito.\n      - type: blog-yfm-block\n        column: left\n        resetPaddings: true\n        text: \"\\n## Existem alternativas?{#analogs}\\n\\nHoje o mercado tem muitas soluções para desenhar grafos, desde soluções pagas como [yFiles](https://yfiles.dev/){target=\\\"_blank\\\"}, [JointJS](https://github.com/clientIO/joint){target=\\\"_blank\\\"}, até soluções open source como [Foblex Flow](https://github.com/Foblex/f-flow){target=\\\"_blank\\\"}, [baklavajs](https://github.com/newcat/baklavajs){target=\\\"_blank\\\"}, [jsPlumb](https://github.com/jsplumb/community-edition){target=\\\"_blank\\\"}. Mas, para comparação, consideramos [@antv/g6](https://github.com/antvis/G6){target=\\\"_blank\\\"} e [React Flow](https://github.com/xyflow/xyflow){target=\\\"_blank\\\"} como as ferramentas mais populares. Cada uma tem suas características.\\n\\nReact Flow é uma boa biblioteca voltada para construir interfaces node‑based. Ela tem recursos muito amplos, mas devido ao uso de svg e html tem uma performance relativamente modesta. A biblioteca é boa quando há certeza de que os grafos não vão passar de 100–200 blocos.\\n\\nPor sua vez, o @antv/g6 tem um monte de recursos; ele suporta Canvas e, em particular, WebGL. Comparar diretamente @antv/g6 e @gravity‑ui/graph talvez não faça sentido: eles são mais voltados para construção de grafos e diagramas — mas UI node‑based também é suportado. Então o antv/g6 serve se, além de uma interface node‑based, você também precisa desenhar gráficos/diagramas.\\n\\nEmbora a biblioteca @antv/g6 saiba tanto canvas/webgl quanto html/svg, o controle das regras de alternância vai ter que ser feito manualmente — e é preciso fazer isso corretamente. Em performance, ela é muito mais rápida do que React Flow, mas ainda assim há questões. Embora eles afirmem que há suporte a WebGL, se você olhar o [stress test](https://g6.antv.antgroup.com/en/examples/performance/massive-data#60000){target=\\\"_blank\\\"}, dá para notar que com 60k nós a biblioteca não consegue garantir dinâmica — em um MacBook M3 a renderização de um frame levou 4 segundos. Para comparação, nosso [stress test](https://preview.gravity-ui.com/graph/?path=/story/stories-main-grapheditor--graph-stress-test){target=\\\"_blank\\\"} com 111k nós e 109k conexões no mesmo Macbook M3: a renderização da cena do grafo inteiro leva ~60ms, o que dá ~15–20FPS. Não é muito, mas com Spatial Culling é possível limitar o viewport e assim melhorar a responsividade. Embora os mantenedores tenham [declarado](https://github.com/antvis/G6/issues/1597){target=\\\"_blank\\\"} que querem alcançar renderização de 100k nós a 30 FPS, ao que tudo indica eles ainda não conseguiram.\\n\\nMais um ponto em que @gravity‑ui/graph vence é o tamanho do bundle.\\n\\n#|\\n|||Bundle size Minified|Bundle size Minified + Gzipped||\\n||@antv/g6 [bundlephobia](https://bundlephobia.com/package/@antv/g6@5.0.49){target=\\\"_blank\\\"}|1.1 MB|324.5\\_kB||\\n||react flow [bundlephobia](https://bundlephobia.com/package/@xyflow/react@12.8.1){target=\\\"_blank\\\"}|181.2\\_kB|56.4\\_kB||\\n||@gravity-ui/graph [bundlephobia](https://bundlephobia.com/package/@gravity-ui/graph){target=\\\"_blank\\\"}|2.2\\_kB|672\\_B||\\n|#\\n\\nEmbora as duas bibliotecas sejam bastante fortes em performance ou em facilidade de integração, @gravity‑ui/graph tem uma série de vantagens — ela consegue garantir performance em grafos realmente grandes e, ao mesmo tempo, manter o UI/UX para o usuário e simplificar o desenvolvimento.\\n\"\n      - type: blog-yfm-block\n        column: left\n        resetPaddings: true\n        text: >\n\n          ## Planos para o futuro{#future}\n\n\n          Já agora a biblioteca tem uma boa reserva de performance para\n          a maioria das tarefas, então no curto prazo vamos dar mais atenção ao\n          desenvolvimento do ecossistema ao redor da biblioteca — desenvolver camadas\n          (plugins), integrações para outras bibliotecas e frameworks\n          (Angular/Vue/Svelte, …etc), adicionar suporte a dispositivos touch,\n          adaptação para navegadores móveis e, no geral, melhorar UX/DX.\n      - type: blog-yfm-block\n        column: left\n        resetPaddings: true\n        text: >\n\n          ## Experimente e junte-se a nós{#try}\n\n\n          No [repositório](https://github.com/gravity-ui/graph){target=\"_blank\"}\n          você encontrará uma biblioteca totalmente funcional:\n\n            * Núcleo em Canvas + R‑Tree (≈ 30K linhas de código),\n            * integração React,\n            * Storybook com exemplos.\n\n          Você pode instalar a biblioteca com uma única linha:\n\n\n          `npm install @gravity-ui/graph`\n\n\n          --------------\n\n\n          Por bastante tempo, a biblioteca que hoje se chama @gravity‑ui/graph\n          foi uma ferramenta interna dentro do Nirvana, e a abordagem escolhida se\n          mostrou muito eficaz. Agora queremos compartilhar nossos desenvolvimentos\n          e ajudar desenvolvedores de fora a desenhar seus grafos de forma mais simples, rápida e\n          performática.\n\n\n          Queremos padronizar abordagens para exibição de grafos complexos na\n          comunidade open source — há equipes demais reinventando a roda ou\n          sofrendo com ferramentas inadequadas.\n\n\n          Por isso, é muito importante para nós coletar seu feedback — projetos diferentes trazem\n          edge cases diferentes, que ajudam a evoluir a biblioteca. Isso\n          vai nos ajudar a aprimorá-la e a crescer mais rápido o ecossistema Gravity\n          UI.\n  - type: blog-layout-block\n    resetPaddings: true\n    fullWidth: false\n    children:\n      - type: blog-meta-block\n        column: left\n        resetPaddings: true\n  - type: blog-suggest-block\n    resetPaddings: true\n",
    "title": "",
    "noIndex": false,
    "shareTitle": null,
    "shareDescription": null,
    "shareImage": null,
    "pageLocaleId": null,
    "author": "timofeyevvv",
    "metaDescription": null,
    "keywords": [],
    "shareGenTitle": null,
    "canonicalLink": null,
    "sharingType": "auto",
    "sharingTheme": "light",
    "comment": "initial",
    "shareImageUrl": "https://storage.cloud-preprod.yandex.net/ui-api-ru-preprod-stable-share-generator-screenshots/cache/292d9f3e0a443a096ee408a6f28fc6fec674eb78.png",
    "pageRegionId": 75,
    "summary": null,
    "versionId": 199,
    "service": null,
    "solution": null,
    "locales": [
      {
        "id": 75,
        "pageId": 71,
        "locale": "pt",
        "createdAt": "2026-01-15T11:26:48.440Z",
        "updatedAt": "2026-01-15T11:26:48.519Z",
        "publishedVersionId": null,
        "lastVersionId": 195
      },
      {
        "id": 76,
        "pageId": 71,
        "locale": "en",
        "createdAt": "2026-01-15T11:26:48.532Z",
        "updatedAt": "2026-01-15T11:26:48.609Z",
        "publishedVersionId": null,
        "lastVersionId": 196
      }
    ],
    "pageRegions": [
      {
        "regionCode": "en",
        "publishedVersionId": null
      },
      {
        "regionCode": "pt-br",
        "publishedVersionId": 199
      }
    ],
    "searchCategory": {
      "id": 7,
      "slug": "blog",
      "title": "Blog",
      "url": "/blog"
    },
    "voiceovers": []
  }
  
{
    "id": 71,
    "name": "blog/graph",
    "createdAt": "2026-01-15T13:00:46.903Z",
    "updatedAt": "2026-01-15T13:00:46.903Z",
    "type": "default",
    "isDeleted": false,
    "versionOnTranslationId": null,
    "searchCategorySlug": "blog",
    "regions": [],
    "pageId": 71,
    "regionCode": "en",
    "publishedVersionId": 216,
    "lastVersionId": 216,
    "content": "blocks:\n  - type: blog-header-block\n    resetPaddings: true\n    paddingBottom: l\n    width: m\n    verticalOffset: m\n    theme: dark\n    background:\n      image:\n        src: >-\n          https://storage.yandexcloud.net/gravity-landing-static/blog/blog-cover-bg.png\n        disableCompress: true\n      color: '#CCDAFF'\n      fullWidth: false\n  - type: blog-layout-block\n    resetPaddings: true\n    mobileOrder: reverse\n    children:\n      - type: blog-yfm-block\n        resetPaddings: true\n        column: right\n        text: >\n\n          ![image](https://storage.yandexcloud.net/gravity-landing-static/blog/canvas-vs-html/speaker.jpg\n          =80x)\n\n\n          **Andrej Schtschetinin**\n\n          Senior Frontend-Entwickler\n      - type: blog-yfm-block\n        column: right\n        resetPaddings: true\n        text: |\n\n          In diesem Artikel:\n\n            - [Woher die Aufgabe kam](#task)\n            - [Wie wir zur Lösung gekommen sind](#solution)\n            - [Anpassung](#customization)\n            - [Unsere Graph-Bibliothek: Vorteile und Nutzung](#library)\n            - [Gibt es Alternativen?](#analogs)\n            - [Pläne für die Zukunft](#future)\n            - [Ausprobieren und mitmachen](#try)\n      - type: blog-yfm-block\n        column: left\n        resetPaddings: true\n        text: >\n\n          Hallo! Ich heiße Andrej und bin Frontend-Entwickler im User-Experience-Team\n          der Infrastruktur-Services bei Yandex. Wir entwickeln Gravity UI\n          — ein Open-Source-Designsystem und eine React-Komponentenbibliothek, die\n          von Dutzenden Produkten innerhalb des Unternehmens und darüber hinaus genutzt wird.\n          Heute erzähle ich, wie wir vor der Aufgabe standen, komplexe\n          Graphen zu visualisieren, warum uns bestehende Lösungen nicht überzeugt haben\n          und wie schließlich @gravity‑ui/graph entstand — eine Bibliothek, die wir\n          für die Community geöffnet haben.\n\n\n          Diese Geschichte begann mit einem praktischen Problem: Wir mussten\n          Graphen mit 10.000+ Elementen inklusive interaktiver Komponenten rendern. Bei Yandex gibt es\n          viele Projekte, in denen Benutzer komplexe Datenverarbeitungs-Pipelines erstellen —\n          von einfachen ETL-Prozessen bis hin zu Machine Learning. Wenn solche\n          Pipelines programmatisch erzeugt werden, kann die Anzahl der Blöcke\n          Zehntausende erreichen.\n\n\n          Bestehende Lösungen haben uns nicht zufrieden gestellt:\n\n            * **HTML/SVG-Bibliotheken** sehen gut aus und sind bequem in der Entwicklung, werden aber schon bei Hunderten von Elementen langsam.\n            * **Canvas-Lösungen** sind performant, erfordern aber extrem viel Code, um komplexe UI-Elemente zu bauen.\n\n          Einen Button mit abgerundeten Ecken und Gradient in Canvas zu zeichnen,\n          ist nicht schwer. Probleme beginnen jedoch, wenn man eigene komplexe\n          Controls oder Layouts erstellen muss — dann braucht man Dutzende Zeilen\n          an Low-Level-Zeichenbefehlen. Jedes UI-Element muss man\n          von Grund auf programmieren — von Klick-Handling bis zu Animationen.\n          Wir brauchten aber vollwertige UI-Komponenten: Buttons, Selects, Eingabefelder,\n          Drag-and-drop.\n\n\n          Wir wollten nicht zwischen Canvas und HTML wählen, sondern das Beste\n          aus beiden Technologien nutzen. Die Idee war einfach: automatisch\n          zwischen Modi umschalten — abhängig davon, wie nah der Nutzer\n          auf den Graphen zoomt.\n      - type: blog-media-block\n        column: left\n        resetPaddings: true\n        paddingBottom: s\n        text: ''\n        image:\n          src: >-\n            https://storage.yandexcloud.net/gravity-landing-static/blog/canvas-vs-html/pic1.png\n        fullscreen: true\n      - type: blog-yfm-block\n        column: left\n        resetPaddings: true\n        text: |\n\n          #### Probieren Sie es selbst aus\n\n            * [GitHub-Repository](https://github.com/gravity-ui/graph){target=\"_blank\"}\n            * [Storybook mit Beispielen](https://preview.gravity-ui.com/graph/){target=\"_blank\"}\n            * [Playground](https://gravity-ui.com/ru/libraries/graph/playground){target=\"_blank\"}\n      - type: blog-yfm-block\n        column: left\n        resetPaddings: true\n        text: >\n\n          ## Woher die Aufgabe kam{#task}\n\n\n          ### Nirvana und ihre Graphen\n\n\n          Bei Yandex gibt es den Service Nirvana zum Erstellen und Ausführen von\n          Datenverarbeitungs-Graphen (darüber haben wir\n          [bereits](https://habr.com/ru/companies/yandex/articles/351016/){target=\"_blank\"}\n          schon 2018 geschrieben). Der Service ist groß, beliebt und existiert schon lange.\n\n\n          Ein Teil der Nutzer erstellt Graphen manuell — mit der Maus, fügt\n          Blöcke hinzu und verbindet sie. Solche Graphen sind unproblematisch:\n          Es gibt nicht viele Blöcke, und alles funktioniert hervorragend. Aber es gibt Projekte,\n          die Graphen programmatisch erzeugen. Und hier beginnen die Schwierigkeiten:\n          Sie können bis zu 10.000 Operationen in einen einzigen Graphen packen. Das sieht dann so aus:\n      - type: blog-media-block\n        column: left\n        resetPaddings: true\n        text: ''\n        image:\n          src: >-\n            https://storage.yandexcloud.net/gravity-landing-static/blog/canvas-vs-html/pic2.png\n        fullscreen: true\n      - type: blog-yfm-block\n        column: left\n        resetPaddings: true\n        text: >\n\n          {% cut \"Und so:\" %}\n\n\n          ![image](https://storage.yandexcloud.net/gravity-landing-static/blog/canvas-vs-html/pic2-1.png\n          =830x)\n\n          ![image](https://storage.yandexcloud.net/gravity-landing-static/blog/canvas-vs-html/pic2-2.png\n          =830x)\n\n          ![image](https://storage.yandexcloud.net/gravity-landing-static/blog/canvas-vs-html/pic2-3.png\n          =830x)\n\n          ![image](https://storage.yandexcloud.net/gravity-landing-static/blog/canvas-vs-html/pic2-4.png\n          =830x)\n\n          ![image](https://storage.yandexcloud.net/gravity-landing-static/blog/canvas-vs-html/pic2-5.png\n          =830x)\n\n\n          {% endcut %}\n\n\n          Solche Graphen schafft eine gewöhnliche Kombination aus HTML + SVG einfach nicht.\n          Der Browser wird langsam, Speicher läuft aus, der Nutzer leidet. Wir haben versucht,\n          das Problem direkt zu lösen: HTML-Rendering zu optimieren, sind aber früher oder später\n          an physische Grenzen gestoßen — das DOM ist schlicht nicht dafür ausgelegt,\n          Tausende gleichzeitig sichtbare, frei schwebende interaktive Elemente zu verwalten.\n\n\n          Es braucht eine andere Lösung, und im Browser blieb uns nur Canvas.\n          Nur damit lässt sich die erforderliche Performance erreichen.\n\n\n          Der erste Gedanke: eine fertige Lösung finden. Es war 2017–2018, und wir\n          haben populäre Bibliotheken für Canvas oder Graph-Rendering durchforstet,\n          aber alle stießen auf dasselbe Problem: Entweder Canvas mit primitiven Elementen,\n          oder HTML/SVG und dafür Performance opfern.\n\n\n          Was, wenn man nicht wählen müsste?\n\n\n          ### Level of Details: Inspiration aus GameDev\n\n\n          In GameDev und Kartografie gibt es ein großartiges Konzept — Level of Details\n          (LOD). Diese Technik entstand aus der Notwendigkeit: Wie zeigt man eine riesige Welt,\n          ohne die Performance zu zerstören?\n\n\n          Die Idee ist simpel: Ein Objekt kann mehrere Detailstufen haben — abhängig davon,\n          wie nah man hinschaut. In Spielen sieht man das besonders deutlich:\n\n            * In der Ferne sieht man Berge — einfache Polygone mit Basistextur.\n            * Kommt man näher, erscheinen Details: Gras, Steine, Schatten.\n            * Noch näher sieht man einzelne Blätter an den Bäumen.\n\n          Niemand rendert Millionen Gras-Polygone, wenn der Spieler auf einem Berggipfel steht\n          und in die Ferne blickt.\n\n\n          Bei Karten ist das Prinzip dasselbe — für jede Zoomstufe gibt es eigene Daten\n          und eine eigene Detailtiefe:\n\n            * Kontinent-Maßstab — man sieht nur Länder.\n            * Zoomt man in eine Stadt, erscheinen Straßen und Bezirke.\n            * Noch näher — Hausnummern, Cafés, Bushaltestellen.\n\n          Uns wurde klar: Der Nutzer braucht auf einer Gesamtansicht eines Graphen mit 10.000 Blöcken\n          keine interaktiven Buttons — er sieht sie ohnehin nicht und kann damit nicht arbeiten.\n\n\n          Mehr noch: Der Versuch, 10.000 HTML-Elemente gleichzeitig zu rendern,\n          friert den Browser ein. Wenn man aber in einen konkreten Bereich zoomt,\n          fällt die Zahl der sichtbaren Blöcke drastisch — von 10.000 auf z. B. 50.\n          Genau dann werden Ressourcen frei für HTML-Komponenten mit reichhaltiger Interaktivität.\n\n\n          ### Drei Ebenen unseres Level-of-Details-Schemas\n\n\n          #### Minimalistic (Zoom 0,1–0,3) — Canvas mit einfachen Primitive\n\n\n          In diesem Modus sieht der Nutzer die Gesamtarchitektur des Systems: wo\n          die Hauptgruppen von Blöcken liegen und wie sie miteinander verbunden sind.\n          Jeder Block ist ein einfaches Rechteck mit grundlegender Farbcodierung.\n          Keine Texte, Buttons, detaillierten Icons. Dafür kann man komfortabel\n          Tausende von Elementen rendern. Auf dieser Ebene wählt der Nutzer den Bereich\n          für eine detaillierte Betrachtung.\n      - type: blog-media-block\n        column: left\n        resetPaddings: true\n        paddingBottom: s\n        text: ''\n        image:\n          src: >-\n            https://storage.yandexcloud.net/gravity-landing-static/blog/canvas-vs-html/pic3.png\n        fullscreen: true\n      - type: blog-yfm-block\n        column: left\n        resetPaddings: true\n        text: >\n\n          #### Schematic (Zoom 0,3–0,7) — Canvas mit Details\n\n\n          Es erscheinen Blocknamen, Status-Icons, Anker für Verbindungen.\n          Text wird mit dem Canvas-API gerendert — das ist schnell, aber die Styling-Möglichkeiten\n          sind begrenzt. Die Verbindungen zwischen den Blöcken werden informativer:\n          Man kann die Richtung des Datenflusses und den Verbindungsstatus zeigen.\n          Das ist ein Übergangsmodus, in dem Canvas-Performance mit grundlegender Informationsdichte\n          kombiniert wird.\n      - type: blog-media-block\n        column: left\n        resetPaddings: true\n        paddingBottom: s\n        text: ''\n        image:\n          src: >-\n            https://storage.yandexcloud.net/gravity-landing-static/blog/canvas-vs-html/pic4.png\n        fullscreen: true\n      - type: blog-yfm-block\n        column: left\n        resetPaddings: true\n        text: >\n\n          #### Detailed (Zoom 0,7+) — HTML mit voller Interaktivität\n\n\n          Hier werden Blöcke zu vollwertigen UI-Komponenten: mit\n          Steuerbuttons, Parameterfeldern, Progress-Bars,\n          Selects. Man kann alle Möglichkeiten von HTML/CSS nutzen und\n          UI-Bibliotheken anbinden. In diesem Modus passen in den Viewport\n          üblicherweise nicht mehr als 20–50 Blöcke — komfortabel für detaillierte Arbeit.\n      - type: blog-media-block\n        column: left\n        resetPaddings: true\n        text: ''\n        image:\n          src: >-\n            https://storage.yandexcloud.net/gravity-landing-static/blog/canvas-vs-html/pic5.png\n        fullscreen: true\n      - type: blog-yfm-block\n        column: left\n        resetPaddings: true\n        text: >\n\n          **Was wäre, wenn man FPS zur Wahl der Detailstufe nutzt?**\n\n\n          Wir hatten Ansätze, die Detailstufe anhand der FPS zu wählen. Es stellte sich aber heraus,\n          dass so ein Ansatz Instabilität erzeugt: Steigt die Performance, schaltet das System\n          in einen detaillierteren Modus, was die FPS senkt und ein Zurückschalten auslösen kann —\n          und so weiter im Kreis.\n      - type: blog-yfm-block\n        column: left\n        resetPaddings: true\n        text: >\n\n          ## Wie wir zur Lösung gekommen sind{#solution}\n\n\n          Gut, LOD ist großartig. Aber die Umsetzung erfordert Canvas für Performance —\n          und das ist ein neues Kopfzerbrechen. Auf Canvas zu zeichnen ist\n          nicht sehr schwierig — Probleme beginnen, wenn Interaktivität nötig ist.\n\n\n          ### Problem: Wie erkennt man, wohin der Nutzer geklickt hat?\n\n\n          In HTML ist es einfach: Auf einen Button geklickt — das Event landet direkt am Element.\n          Bei Canvas ist es schwieriger: Auf die Zeichenfläche geklickt — und was dann?\n          Man muss selbst herausfinden, auf welches Element der Nutzer geklickt hat.\n\n\n          Grundsätzlich gibt es drei Ansätze:\n\n            * Pixel Testing (Color Picking),\n            * Geometric approach (einfaches Durchlaufen aller Elemente),\n            * Spatial Indexing (räumlicher Index).\n\n          #### Pixel Testing (Color Picking)\n\n\n          Die Idee ist simpel: Wir erstellen ein zweites unsichtbares Canvas, kopieren die Szene dorthin,\n          aber füllen jedes Element mit einer eindeutigen Farbe, die als Objekt-ID gilt.\n          Beim Klick lesen wir die Pixelfarbe unter dem Mauszeiger via getImageData aus\n          und erhalten so die Element-ID.\n\n\n          #|\n\n          ||**Vorteile**|**Nachteile**||\n\n          ||* In ein paar Dutzend Zeilen umsetzbar\n\n\n          * Benötigt keine zusätzlichen Datenstrukturen|* Canvas-Anti-Aliasing mischt Farben — ein Klick auf die Formgrenze kann eine „ungültige“ ID liefern\n\n\n          * Anti-Aliasing im 2D-Canvas lässt sich nicht deaktivieren\n\n\n          * Das zweite Canvas verdoppelt den Speicherverbrauch und den Render-Pass||\n\n          |#\n\n\n          Für kleine Szenen ist die Methode ok, aber bei 10.000+ Elementen wird die Fehlerquote\n          inakzeptabel — Pixel Testing legen wir beiseite.\n\n\n          #### Geometric approach (einfaches Durchlaufen aller Elemente)\n\n\n          Die Idee ist simpel: Wir gehen alle Elemente durch und prüfen, ob der Klickpunkt\n          innerhalb eines Elements liegt.\n\n\n          #|\n\n          ||**Vorteile**|**Nachteile**||\n\n          ||* In ein paar Dutzend Zeilen umsetzbar\n\n\n          * Benötigt keine zusätzlichen Datenstrukturen|* Sehr langsam bei großer Elementanzahl\n\n\n          * Nicht geeignet für große Szenen||\n\n          |#\n\n\n          #### Spatial Indexing\n\n\n          Eine Weiterentwicklung des geometrischen Ansatzes. Dort waren wir an der Anzahl der Elemente\n          gescheitert. Algorithmen für räumliche Indizes versuchen, nahe beieinander liegende Elemente\n          zu gruppieren (meist über Bäume), wodurch die Komplexität auf log n reduziert werden kann.\n\n\n          Es gibt viele Spatial-Index-Algorithmen; wir haben die Datenstruktur R-Tree gewählt,\n          konkret die Bibliothek\n          [rbush](https://github.com/mourner/rbush){target=\"_blank\"}.\n\n\n          R-Tree ist, wie der Name andeutet, ein Baum, in dem jedes Objekt in ein minimal großes\n          Bounding-Rectangle (MBR) gelegt wird; diese Rechtecke werden dann zu größeren Rechtecken\n          gruppiert. So entsteht ein Baum, in dem jedes Rechteck andere Rechtecke enthält.\n      - type: blog-media-block\n        column: left\n        resetPaddings: true\n        text: >-\n          Bild aus Wikipedia\n          [R‑tree](https://en.wikipedia.org/wiki/R-tree){target=\"_blank\"}\n        image:\n          src: >-\n            https://storage.yandexcloud.net/gravity-landing-static/blog/canvas-vs-html/pic6.png\n        fullscreen: true\n      - type: blog-yfm-block\n        column: left\n        resetPaddings: true\n        text: >\n\n          Für die Suche im RTree müssen wir im Baum nach unten steigen (in die Tiefe\n          des Rechtecks), bis wir beim konkreten Element ankommen. Der Pfad wird über die\n          Schnittprüfung des Suchrechtecks mit den MBRs gewählt. Alle Äste, deren Bounding-Box\n          das Suchrechteck nicht einmal berührt, werden sofort verworfen — deshalb ist die\n          Traversierungstiefe meist auf 3–5 Ebenen begrenzt, und die Suche dauert selbst bei\n          Zehntausenden Elementen nur Mikrosekunden.\n\n\n          Diese Variante ist zwar langsamer (O(log n) im besten Fall und O(n) im schlechtesten),\n          als Pixel Testing, dafür aber genauer und weniger speicherhungrig.\n\n\n          #### Ereignismodell\n\n\n          Auf Basis des RTree können wir nun unser Ereignismodell aufbauen.\n          Wenn der Nutzer klickt, starten wir einen Hit-Test: Wir bilden ein Rechteck der Größe\n          1×1 Pixel in Cursor-Koordinaten und suchen seine Schnittmenge im R-Tree.\n          Haben wir das Element gefunden, in das dieses Rechteck fällt, delegieren wir das Event\n          an dieses Element. Wenn das Element das Event nicht stoppt, wird es an den Parent\n          weitergereicht — bis zur Root. Das Verhalten ähnelt dem uns vertrauten\n          Browser-Eventmodell. Events können abgefangen, prevented oder die Bubbling-Phase\n          gestoppt werden.\n\n\n          Wie bereits erwähnt, bilden wir beim Hit-Test ein Rechteck von 1×1 Pixel.\n          Das bedeutet: Wir können ein Rechteck beliebiger Größe bilden. Das hilft uns bei einer\n          weiteren sehr wichtigen Optimierung — Spatial Culling.\n\n\n          ### Spatial Culling\n\n\n          Spatial Culling ist eine Rendering-Optimierungstechnik mit dem Ziel,\n          nichts zu zeichnen, was nicht sichtbar ist. Zum Beispiel zeichnet man keine Objekte,\n          die außerhalb des Kameraraums liegen oder von anderen Elementen verdeckt werden.\n          Da unser Graph in einem 2D-Raum gezeichnet wird, reicht es, nur jene Objekte\n          nicht zu zeichnen, die außerhalb des Sichtbereichs der Kamera (Viewport) liegen.\n\n\n          So funktioniert es:\n\n            * bei jeder Kamerabewegung oder jedem Zoom bilden wir ein Rechteck, das dem aktuellen Viewport entspricht;\n            * wir suchen seine Schnittmenge im R-Tree;\n            * das Ergebnis ist eine Liste der tatsächlich sichtbaren Elemente;\n            * wir rendern nur diese — alles andere wird übersprungen.\n\n          Diese Technik macht die Performance fast unabhängig von der Gesamtanzahl der Elemente:\n          Wenn 40 Blöcke im Bild sind, zeichnet die Bibliothek genau 40 — nicht Zehntausende,\n          die außerhalb des Bildschirms liegen. Bei weiten Zoomstufen fallen viele Elemente in den Viewport,\n          daher zeichnen wir leichte Canvas-Primitive; beim Heranzoomen sinkt die Elementanzahl und die\n          frei werdenden Ressourcen erlauben den Wechsel in den HTML-Modus mit voller Detailtiefe.\n\n\n          Alles zusammen ergibt ein einfaches Schema:\n\n            * Canvas steht für Geschwindigkeit,\n            * HTML für Interaktivität,\n            * R-Tree und Spatial Culling verbinden beides unauffällig zu einem System, das schnell bestimmen kann, welche Elemente auf der HTML-Ebene gezeichnet werden können.\n\n          Während sich die Kamera bewegt, fragt der kleine Viewport beim R-Tree nur jene Objekte ab,\n          die sich tatsächlich im Bild befinden. Dieser Ansatz erlaubt uns, wirklich große Graphen zu zeichnen\n          oder zumindest Performance-Reserven zu haben, bis der Nutzer den Viewport einschränkt.\n\n\n          Im Kern enthält die Bibliothek:\n\n            * Canvas-Modus mit einfachen Primitiven;\n            * HTML-Modus mit voller Detailtiefe;\n            * R-Tree und Spatial Culling zur Performance-Optimierung;\n            * ein gewohntes Ereignismodell.\n\n          Für Produktion reicht das jedoch nicht: Man braucht die Möglichkeit,\n          die Bibliothek zu erweitern und an die eigenen Bedürfnisse anzupassen.\n      - type: blog-yfm-block\n        column: left\n        resetPaddings: true\n        text: >\n\n          ## Anpassung{#customization}\n\n\n          Die Bibliothek bietet zwei sich ergänzende Wege, Verhalten zu erweitern und zu verändern:\n\n            * Überschreiben von Basiskomponenten. Wir ändern die Logik der Standard-Block-, Anchor- und Connection-Komponenten.\n            * Erweiterung über Layer. Wir fügen grundsätzlich neue Funktionalität über/unter der bestehenden Szene hinzu.\n\n          ### Komponenten überschreiben\n\n\n          Wenn man das Aussehen oder Verhalten bereits vorhandener Elemente modifizieren muss,\n          erbt man von der Basisklasse und überschreibt die Schlüsselmethoden.\n          Danach registriert man die Komponente unter einem eigenen Namen.\n\n\n          #### Blöcke anpassen\n\n\n          Wenn Sie z. B. einen Graphen mit Progress-Bars auf den Blöcken erstellen müssen —\n          etwa um den Ausführungsstatus von Tasks in einer Pipeline zu zeigen —\n          können Sie die Standardblöcke leicht anpassen:\n\n\n          ```json\n\n          import { CanvasBlock } from \"@gravity‑ui/graph\";\n\n\n          class ProgressBlock extends CanvasBlock {\n            // Grundform des Blocks mit abgerundeten Ecken\n            public override renderBody(ctx: CanvasRenderingContext2D): void {\n              ctx.fillStyle = \"#ddd\";\n              ctx.beginPath();\n              ctx.roundRect(this.state.x, this.state.y, this.state.width, this.state.height, 12);\n              ctx.fill();\n              ctx.closePath();\n            }\n\n            public renderSchematicView(ctx: CanvasRenderingContext2D): void {\n              const progress = this.state.meta?.progress || 0;\n\n              // Basis des Blocks zeichnen\n              this.renderBody(ctx);\n\n              // Progress-Bar mit Farbindikation\n              const progressWidth = (this.state.width - 20) * (progress / 100);\n              ctx.fillStyle = progress < 50 ? \"#ff6b6b\" : progress < 80 ? \"#feca57\" : \"#48cae4\";\n              ctx.fillRect(this.state.x + 10, this.state.y + this.state.height - 15, progressWidth, 8);\n\n              // Rahmen der Progress-Bar\n              ctx.strokeStyle = \"#ddd\";\n              ctx.lineWidth = 1;\n              ctx.strokeRect(this.state.x + 10, this.state.y + this.state.height - 15, this.state.width - 20, 8);\n\n              // Text mit Prozenten und Name\n              ctx.fillStyle = \"#2d3436\";\n              ctx.font = \"12px Arial\";\n              ctx.textAlign = \"center\";\n              ctx.fillText(`${Math.round(progress)}%`, this.state.x + this.state.width / 2, this.state.y + 20);\n              ctx.fillText(this.state.name, this.state.x + this.state.width / 2, this.state.y + 40);\n            }\n          }\n\n          ```\n\n\n          #### Verbindungen anpassen\n\n\n          Analog dazu: Wenn Sie Verhalten und Aussehen der Kanten ändern müssen —\n          z. B. um die Intensität des Datenflusses zwischen Blöcken darzustellen —\n          können Sie eine eigene Verbindung erstellen:\n\n\n          ```json\n\n          import { BlockConnection } from \"@gravity-ui/graph\";\n\n\n          class DataFlowConnection extends BlockConnection {\n            public override style(ctx: CanvasRenderingContext2D) {\n              // Daten über den Fluss aus verbundenen Blöcken holen\n              const sourceBlock = this.sourceBlock;\n              const targetBlock = this.targetBlock;\n\n              const sourceProgress = sourceBlock?.state.meta?.progress || 0;\n              const targetProgress = targetBlock?.state.meta?.progress || 0;\n\n              // Flussintensität auf Basis des Block-Fortschritts berechnen\n              const flowRate = Math.min(sourceProgress, targetProgress);\n              const isActive = flowRate > 10; // Fluss ist aktiv bei Fortschritt > 10%\n\n              if (isActive) {\n                // Aktiver Fluss -- dicke grüne Linie\n                ctx.strokeStyle = \"#00b894\";\n                ctx.lineWidth = Math.max(2, Math.min(6, flowRate / 20));\n              } else {\n                // Inaktiver Fluss -- gestrichelte graue Linie\n                ctx.strokeStyle = \"#ddd\";\n                ctx.lineWidth = this.context.camera.getCameraScale();\n                ctx.setLineDash([5, 5]);\n              }\n\n              return { type: \"stroke\" };\n            }\n          }\n\n          ```\n\n\n          #### Nutzung eigener Komponenten\n\n\n          Wir registrieren die erstellten Komponenten in den Graph-Einstellungen:\n\n\n          ```json\n\n          const customGraph = new Graph({\n            blocks: [\n              {\n                id: \"task1\",\n                is: \"progress\",\n                x: 100,\n                y: 100,\n                width: 200,\n                height: 80,\n                name: \"Data Processing\",\n                meta: { progress: 75 },\n              },\n              {\n                id: \"task2\",\n                is: \"progress\",\n                x: 400,\n                y: 100,\n                width: 200,\n                height: 80,\n                name: \"Analysis\",\n                meta: { progress: 30 },\n              },\n              {\n                id: \"task3\",\n                is: \"progress\",\n                x: 700,\n                y: 100,\n                width: 200,\n                height: 80,\n                name: \"Output\",\n                meta: { progress: 5 },\n              },\n            ],\n            connections: [\n              { sourceBlockId: \"task1\", targetBlockId: \"task2\" },\n              { sourceBlockId: \"task2\", targetBlockId: \"task3\" },\n            ],\n            settings: {\n              // Eigene Blöcke registrieren\n              blockComponents: {\n                'progress': ProgressBlock,\n              },\n              // Eigene Verbindung für alle Kanten registrieren\n              connection: DataFlowConnection,\n              useBezierConnections: true,\n            },\n          });\n\n\n          customGraph.setEntities({\n            blocks: [\n              {\n              is: 'progress',\n              id: '1',\n              name: \"progress block',\n              x: 10, \n              y: 10, \n              width: 10, \n              height: 10,\n              anchors: [],\n              selected: false,\n              }\n            ]\n          })\n\n\n          customGraph.start();\n\n          ```\n\n\n          #### Ergebnis\n\n\n          Das Resultat ist ein Graph, in dem:\n\n            * Blöcke den aktuellen Fortschritt mit Farbindikation anzeigen;\n            * Verbindungen den Datenfluss visualisieren: aktive Flüsse sind grün und dick, inaktive grau und gestrichelt;\n            * beim Zoomen Blöcke automatisch in den HTML-Modus mit voller Interaktivität wechseln.\n\n          ### Erweiterung über Layer\n\n\n          Layer sind zusätzliche Canvas- oder HTML-Elemente, die in den „Raum“ des Graphen\n          eingefügt werden. Im Grunde ist jeder Layer ein eigener Rendering-Kanal, der\n          entweder ein eigenes Canvas für schnelle Grafik oder einen HTML-Container für\n          komplexe interaktive Elemente enthalten kann.\n\n\n          Übrigens: Genau über Layer funktioniert die React-Integration unserer Bibliothek:\n          React-Komponenten werden in den HTML-Layer via React Portal gerendert.\n\n\n          #### Layer-Architektur\n\n\n          Layer sind noch eine weitere Schlüssellösung für das Canvas-vs-HTML-Dilemma.\n          Layer synchronisieren die Positionen von Canvas- und HTML-Elementen und sorgen\n          für korrektes Überlagern. Dadurch kann man nahtlos zwischen Canvas und HTML wechseln\n          und bleibt dabei im selben Koordinatenraum. Der Graph besteht aus unabhängigen\n          Layern, die übereinander liegen:\n      - type: blog-media-block\n        column: left\n        resetPaddings: true\n        text: ''\n        image:\n          src: >-\n            https://storage.yandexcloud.net/gravity-landing-static/blog/canvas-vs-html/pic7.png\n        fullscreen: true\n      - type: blog-yfm-block\n        column: left\n        resetPaddings: true\n        text: >\n\n          Layer können in zwei Koordinatensystemen arbeiten:\n\n            * An den Graph gebunden (`transformByCameraPosition: true`):\n\n              * Elemente bewegen sich вместе mit der Kamera,\n              * Blöcke, Verbindungen, Graph-Elemente.\n\n            * Am Bildschirm fixiert (`transformByCameraPosition: false`):\n\n              * bleiben beim Panning an Ort und Stelle,\n              * Toolbars, Legenden, UI-Controls.\n\n          #### Wie die React-Integration aufgebaut ist\n\n\n          Ein Layer mit React-Integration ist ziemlich anschaulich, um zu zeigen, was Layer sind.\n          Schauen wir uns zuerst eine Komponente an, die eine Liste von Blöcken hervorhebt,\n          die sich im sichtbaren Bereich der Kamera befinden. Dazu müssen wir Kameraänderungen\n          abonnieren und nach jeder Änderung eine Schnittprüfung zwischen dem Kamera-Viewport\n          und den Hitboxen der Elemente durchführen.\n\n\n          ```json\n\n          import { Graph } from \"@gravity-ui/graph\";\n\n\n          const BlocksList = ({ graph, renderBlock }: { graph: Graph,\n          renderBlock: (graph: Graph, block: TBlock) => React.JSX.Element }) =>\n          {\n            const [blocks, setBlocks] = useState([]);\n\n            const updateVisibleList = useCallback(() => {\n              const cameraState = graph.cameraService.getCameraState();\n              const CAMERA_VIEWPORT_TRESHOLD = 0.5;\n              const x = -cameraState.relativeX - cameraState.relativeWidth * CAMERA_VIEWPORT_TRESHOLD;\n              const y = -cameraState.relativeY - cameraState.relativeHeight * CAMERA_VIEWPORT_TRESHOLD;\n              const width = -cameraState.relativeX + cameraState.relativeWidth * (1 + CAMERA_VIEWPORT_TRESHOLD) - x;\n              const height = -cameraState.relativeY + cameraState.relativeHeight * (1 + CAMERA_VIEWPORT_TRESHOLD) - y;\n              \n              const blocks = graph\n                .getElementsOverRect(\n                  {\n                    x,\n                    y,\n                    width,\n                    height,\n                  }, // definiert den Bereich, in dem die Blockliste gesucht wird\n                  [CanvasBlock] // definiert die Elementtypen, die im Sichtbereich der Kamera gesucht werden\n                ).map((component) => component.connectedState); // Liste der Block-Modelle holen\n\n                setBlocks(blocks);\n            });\n\n              useGraphEvent(graph, \"camera-change\", ({ scale }) => {\n                if (scale >= 0.7) {\n                  // Wenn der Zoom größer als 0.7 ist, aktualisieren wir die Blockliste\n                  updateVisibleList()\n                  return;\n                }\n                setBlocks([]);\n              });\n\n              return blocks.map(block => <React.Fragment key={block.id}>{renderBlock(graphObject, block)}</React.Fragment>)\n          }\n\n          ```\n\n\n          Jetzt schauen wir uns die Beschreibung des Layers selbst an, der diese Komponente\n          verwenden wird.\n\n\n          ```json\n\n          import { Layer } from '@gravity-ui/graph';\n\n\n          class ReactLayer extends Layer {\n            constructor(props: TReactLayerProps) {\n              super({\n                html: {\n                  zIndex: 3, // Layer über die anderen Layer anheben\n                  classNames: [\"no-user-select\"], // Klasse hinzufügen, um Textauswahl zu deaktivieren\n                  transformByCameraPosition: true, // Layer ist an die Kamera gebunden – bewegt sich also mit der Kamera\n                },\n                ...props,\n              });\n            }\n\n            public renderPortal(renderBlock: <T extends TBlock>(block: T) => React.JSX.Element) {\n              if (!this.getHTML()) {\n                return null;\n              }\n\n              const htmlLayer = this.getHTML() as HTMLDivElement;\n\n              return createPortal(\n                React.createElement(BlocksList, {\n                  graph: this.context.graph,\n                  renderBlock: renderBlock,\n                }),\n                htmlLayer,\n              );\n            }\n          }\n\n          ```\n\n\n          Jetzt können wir diesen Layer in unserer Anwendung verwenden.\n\n\n          ```json\n\n          import { Flex } from \"@gravity-ui/uikit\";\n\n\n          const graph = useMemo(() => new Graph());\n\n          const containerRef = useRef<HTMLDivElement>();\n\n\n          useEffect(() => {\n              if (containerRef.current) {\n                graph.attach(containerRef.current);\n              }\n\n              return () => {\n                graph.detach();\n              };\n            }, [graph, containerRef]);\n\n\n          const reactLayer = useLayer(graph, ReactLayer, {});\n\n\n          const renderBlock = useCallback((graph, block) => <Block graph={graph}\n          block={block}>{block.name}</Block>)\n\n            return (\n              <div>\n                <div style={{ position: \"absolute\", overflow: \"hidden\", width: \"100%\", height: \"100%\" }} ref={containerRef}>\n                  {graph && reactLayer && reactLayer.renderPortal(renderBlock)}\n                </div>\n              </div>\n            );\n          ```\n      - type: blog-yfm-block\n        column: left\n        resetPaddings: true\n        text: >\n\n          Insgesamt ist alles ziemlich einfach. Nichts von dem, was oben beschrieben wurde,\n          müssen Sie selbst schreiben — alles ist bereits implementiert und einsatzbereit.\n      - type: blog-yfm-block\n        column: left\n        resetPaddings: true\n        text: >\n\n          ## Unsere Graph-Bibliothek: Vorteile und Nutzung{#library}\n\n\n          Als wir mit der Bibliothek begonnen haben, war die Hauptfrage:\n          Wie stellen wir sicher, dass der Entwickler nicht zwischen\n          Performance und Entwicklerkomfort wählen muss? Die Antwort lag darin,\n          diese Wahl zu automatisieren.\n\n\n          ### Vorteile\n\n\n          #### Performance + Komfort\n\n\n          [@gravity‑ui/graph](https://github.com/gravity-ui/graph){target=\"_blank\"}\n          schaltet automatisch zwischen Canvas und HTML um — abhängig vom Zoom.\n          Das bedeutet, Sie bekommen:\n\n            * Stabile 60 FPS bei Graphen mit Tausenden von Elementen.\n            * Die Möglichkeit, bei Detailansicht vollwertige HTML-Komponenten mit reichhaltiger Interaktivität zu verwenden.\n            * Ein einheitliches Ereignismodell unabhängig vom Rendering — click, mouseenter funktionieren auf Canvas und in HTML gleich.\n\n          #### Kompatibilität mit UI-Bibliotheken\n\n\n          Einer der größten Vorteile ist die Kompatibilität mit beliebigen UI-Bibliotheken.\n          Wenn Ihr Team nutzt:\n\n            * Gravity UI,\n            * Material‑UI,\n            * Ant Design,\n            * eigene Komponenten.\n\n          …, dann müssen Sie nicht darauf verzichten! Beim Hineinzoomen wechselt der Graph\n          automatisch in den HTML-Modus, in dem gewohnte `Button`,\n          `Select`, `DatePicker` in Ihrem gewünschten Farbschema genauso funktionieren\n          wie in einer normalen React-Anwendung.\n\n\n          #### Framework-agnostisch\n\n\n          Obwohl wir den базalen HTML-Renderer mit React implementiert haben,\n          haben wir die Bibliothek so entwickelt, dass sie framework-agnostisch bleibt.\n          Das heißt: Bei Bedarf können Sie relativ einfach einen Layer mit Integration\n          Ihres bevorzugten Frameworks umsetzen.\n      - type: blog-yfm-block\n        column: left\n        resetPaddings: true\n        text: \"\\n## Gibt es Alternativen?{#analogs}\\n\\nAuf dem Markt gibt es derzeit ziemlich viele Lösungen zum Zeichnen von Graphen — von kostenpflichtigen Lösungen wie [yFiles](https://yfiles.dev/){target=\\\"_blank\\\"} und [JointJS](https://github.com/clientIO/joint){target=\\\"_blank\\\"} bis hin zu Open-Source-Lösungen wie [Foblex Flow](https://github.com/Foblex/f-flow){target=\\\"_blank\\\"}, [baklavajs](https://github.com/newcat/baklavajs){target=\\\"_blank\\\"} und [jsPlumb](https://github.com/jsplumb/community-edition){target=\\\"_blank\\\"}. Für den Vergleich betrachten wir aber [@antv/g6](https://github.com/antvis/G6){target=\\\"_blank\\\"} und [React Flow](https://github.com/xyflow/xyflow){target=\\\"_blank\\\"} als die populärsten Tools. Jedes davon hat свои Besonderheiten.\\n\\nReact Flow ist eine gute Bibliothek, die auf den Aufbau node-basierter Interfaces ausgelegt ist. Sie hat sehr umfangreiche Möglichkeiten, aber aufgrund der Nutzung von SVG und HTML eine eher bescheidene Performance. Die Bibliothek ist gut, wenn man sicher ist, dass die Graphen 100–200 Blöcke nicht überschreiten.\\n\\n@antv/g6 hingegen hat массу Funktionen, unterstützt Canvas und insbesondere WebGL. @antv/g6 und @gravity‑ui/graph kann man vermutlich nicht direkt vergleichen: Das Team ist stärker auf Graphen und Diagramme ausgerichtet, aber node-basiertes UI wird ebenfalls unterstützt. antv/g6 passt also, wenn Ihnen nicht nur node-basiertes UI wichtig ist, sondern auch das Zeichnen von Diagrammen.\\n\\nObwohl @antv/g6 sowohl canvas/webgl als auch html/svg beherrscht, muss man die Umschaltregeln selbst steuern — und zwar richtig. Performance-mäßig ist es deutlich schneller als React Flow, aber es bleiben dennoch Fragen. Obwohl WebGL-Support заявлено ist, sieht man in ihrem [Stresstest](https://g6.antv.antgroup.com/en/examples/performance/massive-data#60000){target=\\\"_blank\\\"}, dass die Bibliothek bei 60k Nodes keine Dynamik liefern kann — auf einem MacBook M3 dauerte das Rendern eines Frames 4 Sekunden. Zum Vergleich: Unser [Stresstest](https://preview.gravity-ui.com/graph/?path=/story/stories-main-grapheditor--graph-stress-test){target=\\\"_blank\\\"} mit 111k Nodes und 109k Kanten auf demselben Macbook M3: Das Rendern der gesamten Graph-Szene dauert ~60ms, was ~15–20 FPS ergibt. Das ist nicht sehr viel, aber dank Spatial Culling kann man den Viewport begrenzen und so die Responsiveness verbessern. Obwohl die Maintainer [angekündigt](https://github.com/antvis/G6/issues/1597){target=\\\"_blank\\\"} haben, 100k Nodes bei 30 FPS rendern zu wollen, scheint ihnen das bislang nicht gelungen zu sein.\\n\\nEin weiterer Punkt, in dem @gravity‑ui/graph gewinnt, ist die Bundle-Größe.\\n\\n#|\\n|||Bundle size Minified|Bundle size Minified + Gzipped||\\n||@antv/g6 [bundlephobia](https://bundlephobia.com/package/@antv/g6@5.0.49){target=\\\"_blank\\\"}|1.1 MB|324.5\\_kB||\\n||react flow [bundlephobia](https://bundlephobia.com/package/@xyflow/react@12.8.1){target=\\\"_blank\\\"}|181.2\\_kB|56.4\\_kB||\\n||@gravity-ui/graph [bundlephobia](https://bundlephobia.com/package/@gravity-ui/graph){target=\\\"_blank\\\"}|2.2\\_kB|672\\_B||\\n|#\\n\\nObwohl beide Bibliotheken entweder in der Performance oder beim Integrationskomfort ziemlich stark sind, hat @gravity‑ui/graph mehrere Vorteile — die Bibliothek kann Performance auf wirklich großen Graphen liefern, dabei UI/UX für den Nutzer bewahren und die Entwicklung vereinfachen.\\n\"\n      - type: blog-yfm-block\n        column: left\n        resetPaddings: true\n        text: >\n\n          ## Pläne für die Zukunft{#future}\n\n\n          Schon сейчас hat die Bibliothek genügend Performance-Reserve für die meisten Aufgaben.\n          Daher werden wir in nächster Zeit mehr Aufmerksamkeit auf den Ausbau des Ökosystems\n          rund um die Bibliothek legen — Layer (Plugins) entwickeln, Integrationen für andere\n          Bibliotheken und Frameworks (Angular/Vue/Svelte, …etc) erstellen, Support für Touch-Geräte\n          hinzufügen, Anpassungen für mobile Browser vornehmen und insgesamt UX/DX verbessern.\n      - type: blog-yfm-block\n        column: left\n        resetPaddings: true\n        text: >\n\n          ## Ausprobieren und mitmachen{#try}\n\n\n          Im [Repository](https://github.com/gravity-ui/graph){target=\"_blank\"}\n          finden Sie eine vollständig funktionierende Bibliothek:\n\n            * Core auf Canvas + R‑Tree (≈ 30K Codezeilen),\n            * React-Integration,\n            * Storybook mit Beispielen.\n\n          Installieren kann man die Bibliothek in einer Zeile:\n\n\n          `npm install @gravity-ui/graph`\n\n\n          --------------\n\n\n          Ziemlich lange war die Bibliothek, die heute @gravity‑ui/graph heißt,\n          ein internes Tool innerhalb von Nirvana — und der gewählte Ansatz hat sich\n          sehr bewährt. Jetzt möchten wir unsere Entwicklungen teilen und Entwicklern\n          außerhalb helfen, ihre Graphen einfacher, schneller und performanter zu zeichnen.\n\n\n          Wir wollen Ansätze zur Darstellung komplexer Graphen in der Open-Source-Community\n          standardisieren — zu viele Teams erfinden das Rad neu oder quälen sich mit ungeeigneten Tools.\n\n\n          Deshalb ist uns Ihr Feedback sehr wichtig: Unterschiedliche Projekte bringen\n          unterschiedliche Edge-Cases, die helfen, die Bibliothek weiterzuentwickeln.\n          Das wird uns helfen, die Bibliothek zu verbessern und das Gravity-UI-Ökosystem schneller auszubauen.\n  - type: blog-layout-block\n    resetPaddings: true\n    fullWidth: false\n    children:\n      - type: blog-meta-block\n        column: left\n        resetPaddings: true\n  - type: blog-suggest-block\n    resetPaddings: true\n",
    "title": "",
    "noIndex": false,
    "shareTitle": null,
    "shareDescription": null,
    "shareImage": "https://storage.yandexcloud.net/gravity-landing-static/blog/blog-cover-bg.png",
    "pageLocaleId": null,
    "author": "timofeyevvv",
    "metaDescription": null,
    "keywords": [],
    "shareGenTitle": null,
    "canonicalLink": null,
    "sharingType": "semi-full",
    "sharingTheme": "dark",
    "comment": "sharing pic",
    "shareImageUrl": "https://storage.cloud-preprod.yandex.net/ui-api-ru-preprod-stable-share-generator-screenshots/cache/b155df2ab692d6e154ff809a7d91b9ad4789de53.png",
    "pageRegionId": 76,
    "summary": null,
    "versionId": 216,
    "service": null,
    "solution": null,
    "locales": [
      {
        "id": 75,
        "pageId": 71,
        "locale": "ru",
        "createdAt": "2026-01-15T11:26:48.440Z",
        "updatedAt": "2026-01-15T11:26:48.519Z",
        "publishedVersionId": null,
        "lastVersionId": 195
      },
      {
        "id": 76,
        "pageId": 71,
        "locale": "en",
        "createdAt": "2026-01-15T11:26:48.532Z",
        "updatedAt": "2026-01-15T11:26:48.609Z",
        "publishedVersionId": null,
        "lastVersionId": 196
      }
    ],
    "pageRegions": [
      {
        "regionCode": "ru-ru",
        "publishedVersionId": 199
      },
      {
        "regionCode": "en",
        "publishedVersionId": 216
      }
    ],
    "searchCategory": {
      "id": 7,
      "slug": "blog",
      "title": "Blog",
      "url": "/blog"
    },
    "voiceovers": []
  }
  
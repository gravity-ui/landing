{
    "id": 71,
    "name": "blog/graph",
    "createdAt": "2026-01-15T13:00:46.903Z",
    "updatedAt": "2026-01-15T13:00:46.903Z",
    "type": "default",
    "isDeleted": false,
    "versionOnTranslationId": null,
    "searchCategorySlug": "blog",
    "regions": [],
    "pageId": 71,
    "regionCode": "en",
    "publishedVersionId": 216,
    "lastVersionId": 216,
    "content": "blocks:\n  - type: blog-header-block\n    resetPaddings: true\n    paddingBottom: l\n    width: m\n    verticalOffset: m\n    theme: dark\n    background:\n      image:\n        src: >-\n          https://storage.yandexcloud.net/gravity-landing-static/blog/blog-cover-bg.png\n        disableCompress: true\n      color: '#CCDAFF'\n      fullWidth: false\n  - type: blog-layout-block\n    resetPaddings: true\n    mobileOrder: reverse\n    children:\n      - type: blog-yfm-block\n        resetPaddings: true\n        column: right\n        text: >\n\n          ![image](https://storage.yandexcloud.net/gravity-landing-static/blog/canvas-vs-html/speaker.jpg\n          =80x)\n\n\n          **Andréi Shchetinin**\n\n          Desarrollador senior de interfaces\n      - type: blog-yfm-block\n        column: right\n        resetPaddings: true\n        text: |\n\n          En este artículo:\n\n            - [De dónde salió la tarea](#task)\n            - [Cómo llegamos a la solución](#solution)\n            - [Personalización](#customization)\n            - [Nuestra biblioteca de grafos: ventajas y cómo usarla](#library)\n            - [¿Y hay alternativas?](#analogs)\n            - [Planes para el futuro](#future)\n            - [Pruébalo y únete](#try)\n      - type: blog-yfm-block\n        column: left\n        resetPaddings: true\n        text: >\n\n          ¡Hola! Me llamo Andréi y soy desarrollador de interfaces en el equipo de User\n          Experience de los servicios de infraestructura de Yandex. Desarrollamos Gravity UI\n          — un sistema de diseño open source y una biblioteca de componentes React que\n          utilizan decenas de productos dentro de la empresa y fuera de ella.\n          Hoy contaré cómo nos encontramos con la tarea de visualizar grafos complejos,\n          por qué las soluciones existentes no nos convencieron y cómo finalmente\n          apareció @gravity‑ui/graph — una biblioteca que decidimos abrir a la comunidad.\n\n\n          Esta historia empezó con un problema práctico: necesitábamos renderizar\n          grafos de 10.000+ elementos con componentes interactivos. En Yandex hay\n          muchos proyectos en los que los usuarios crean pipelines complejos de procesamiento\n          de datos — desde procesos ETL sencillos hasta machine learning. Cuando esos\n          pipelines se generan de forma programática, el número de bloques puede llegar\n          a decenas de miles.\n\n\n          Las soluciones existentes no nos satisfacían:\n\n            * **Bibliotecas HTML/SVG** se ven bien y son cómodas para desarrollar, pero empiezan a ir lentas ya con cientos de elementos.\n            * **Soluciones Canvas** ofrecen rendimiento, pero requieren una enorme cantidad de código para crear elementos de UI complejos.\n\n          Dibujar un botón con esquinas redondeadas y un degradado en Canvas\n          no es difícil. Pero aparecen problemas cuando hay que crear controles\n          complejos propios o maquetación — habrá que escribir decenas de líneas\n          de comandos de dibujo de bajo nivel. Cada elemento de interfaz hay que\n          programarlo desde cero — desde el manejo de clics hasta animaciones.\n          Y nosotros necesitábamos componentes de UI completos: botones, selects,\n          campos de entrada, drag‑and‑drop.\n\n\n          Decidimos no elegir entre Canvas y HTML, sino usar lo mejor\n          de ambas tecnologías. La idea era simple: cambiar automáticamente\n          entre modos según lo cerca que el usuario esté viendo el grafo.\n      - type: blog-media-block\n        column: left\n        resetPaddings: true\n        paddingBottom: s\n        text: ''\n        image:\n          src: >-\n            https://storage.yandexcloud.net/gravity-landing-static/blog/canvas-vs-html/pic1.png\n        fullscreen: true\n      - type: blog-yfm-block\n        column: left\n        resetPaddings: true\n        text: |\n\n          #### Pruébalo tú mismo\n\n            * [Repositorio en GitHub](https://github.com/gravity-ui/graph){target=\"_blank\"}\n            * [Storybook con ejemplos](https://preview.gravity-ui.com/graph/){target=\"_blank\"}\n            * [Playground](https://gravity-ui.com/ru/libraries/graph/playground){target=\"_blank\"}\n      - type: blog-yfm-block\n        column: left\n        resetPaddings: true\n        text: >\n\n          ## De dónde salió la tarea{#task}\n\n\n          ### Nirvana y sus grafos\n\n\n          En Yandex tenemos el servicio Nirvana para crear y ejecutar grafos\n          de procesamiento de datos (sobre él\n          [escribimos](https://habr.com/ru/companies/yandex/articles/351016/){target=\"_blank\"}\n          ya en 2018). Es un servicio grande, popular y existe desde hace mucho.\n\n\n          Parte de los usuarios crea grafos manualmente — con el ratón, añaden\n          bloques, los conectan. Con esos grafos no hay problema: hay pocos bloques y\n          todo funciona excelente. Pero hay proyectos que crean grafos\n          de forma programática. Y ahí empiezan las dificultades:\n          pueden meter en un solo grafo hasta 10.000 operaciones. Y queda algo así:\n      - type: blog-media-block\n        column: left\n        resetPaddings: true\n        text: ''\n        image:\n          src: >-\n            https://storage.yandexcloud.net/gravity-landing-static/blog/canvas-vs-html/pic2.png\n        fullscreen: true\n      - type: blog-yfm-block\n        column: left\n        resetPaddings: true\n        text: >\n\n          {% cut \"Y también así:\" %}\n\n\n          ![image](https://storage.yandexcloud.net/gravity-landing-static/blog/canvas-vs-html/pic2-1.png\n          =830x)\n\n          ![image](https://storage.yandexcloud.net/gravity-landing-static/blog/canvas-vs-html/pic2-2.png\n          =830x)\n\n          ![image](https://storage.yandexcloud.net/gravity-landing-static/blog/canvas-vs-html/pic2-3.png\n          =830x)\n\n          ![image](https://storage.yandexcloud.net/gravity-landing-static/blog/canvas-vs-html/pic2-4.png\n          =830x)\n\n          ![image](https://storage.yandexcloud.net/gravity-landing-static/blog/canvas-vs-html/pic2-5.png\n          =830x)\n\n\n          {% endcut %}\n\n\n          Grafos así, una combinación habitual de HTML + SVG simplemente no los soporta.\n          El navegador empieza a ir lento, hay fugas de memoria y el usuario sufre. Intentamos\n          resolverlo de frente: optimizar el renderizado HTML, pero tarde o temprano\n          chocábamos con límites físicos — el DOM no está pensado para miles de elementos\n          interactivos flotantes visibles al mismo tiempo.\n\n\n          Necesitábamos otra solución, y en el navegador solo nos quedaba Canvas.\n          Solo él puede garantizar el rendimiento necesario.\n\n\n          La primera idea fue encontrar una solución ya hecha. Era 2017–2018, y\n          revisamos bibliotecas populares para Canvas o renderizado de grafos,\n          pero todas tropezaban con el mismo problema: o usas Canvas con elementos\n          primitivos, o usas HTML/SVG sacrificando rendimiento.\n\n\n          ¿Y si no elegimos?\n\n\n          ### Level of Details: inspiración de GameDev\n\n\n          En GameDev y cartografía hay un concepto genial — Level of Details\n          (LOD). Esta técnica nació de una necesidad: ¿cómo mostrar un mundo enorme\n          sin matar el rendimiento?\n\n\n          La idea es simple: un mismo objeto puede tener varios niveles de\n          detalle según lo cerca que se mire. En los juegos se nota especialmente:\n\n            * A lo lejos se ven montañas — polígonos simples con textura básica.\n            * Al acercarte, aparecen detalles: hierba, piedras, sombras.\n            * Aún más cerca, se ven hojas individuales en los árboles.\n\n          Nadie renderiza millones de polígonos de hierba cuando el jugador está\n          en la cima de una montaña mirando a lo lejos.\n\n\n          En los mapas el principio es el mismo — cada nivel de zoom tiene su propio\n          conjunto de datos y su propia granularidad:\n\n            * Zoom de continente — solo se ven países.\n            * Te acercas a una ciudad — aparecen calles y barrios.\n            * Más cerca — números de portal, cafeterías, paradas de autobús.\n\n          Entendimos: el usuario no necesita botones interactivos en una vista\n          general de un grafo de 10.000 bloques — no los verá ni podrá\n          trabajar con ellos.\n\n\n          Además, intentar renderizar 10.000 elementos HTML a la vez\n          congelará el navegador. Pero cuando hace zoom en un área concreta,\n          la cantidad de bloques visibles cae de golpe — de 10.000 a, digamos, 50.\n          Ahí es donde se liberan recursos para componentes HTML con interactividad rica.\n\n\n          ### Tres niveles de nuestro esquema Level of Details\n\n\n          #### Minimalistic (zoom 0,1–0,3) — Canvas con primitivas simples\n\n\n          En este modo el usuario ve la arquitectura general del sistema: dónde\n          están los principales grupos de bloques y cómo se conectan.\n          Cada bloque es un rectángulo simple con codificación de color básica.\n          Sin textos, botones ni iconos detallados. A cambio, se pueden\n          renderizar miles de elementos de forma cómoda. En este nivel el usuario\n          elige el área para un estudio detallado.\n      - type: blog-media-block\n        column: left\n        resetPaddings: true\n        paddingBottom: s\n        text: ''\n        image:\n          src: >-\n            https://storage.yandexcloud.net/gravity-landing-static/blog/canvas-vs-html/pic3.png\n        fullscreen: true\n      - type: blog-yfm-block\n        column: left\n        resetPaddings: true\n        text: >\n\n          #### Schematic (zoom 0,3–0,7) — Canvas con detalles\n\n\n          Aparecen los nombres de los bloques, iconos de estado y anclajes para conexiones.\n          El texto se renderiza con la API de Canvas — es rápido, pero las posibilidades\n          de estilo son limitadas. Las conexiones entre bloques se vuelven más informativas:\n          se puede mostrar la dirección del flujo de datos y el estado de la conexión.\n          Es un modo de transición donde el rendimiento de Canvas se combina con\n          información básica.\n      - type: blog-media-block\n        column: left\n        resetPaddings: true\n        paddingBottom: s\n        text: ''\n        image:\n          src: >-\n            https://storage.yandexcloud.net/gravity-landing-static/blog/canvas-vs-html/pic4.png\n        fullscreen: true\n      - type: blog-yfm-block\n        column: left\n        resetPaddings: true\n        text: >\n\n          #### Detailed (zoom 0,7+) — HTML con interactividad completa\n\n\n          Aquí los bloques se convierten en componentes de interfaz completos: con\n          botones de control, campos de parámetros, barras de progreso,\n          selects. Se puede usar cualquier capacidad de HTML/CSS y conectar\n          bibliotecas de UI. En este modo, normalmente caben en el viewport\n          no más de 20–50 bloques, lo cual es cómodo para trabajo detallado.\n      - type: blog-media-block\n        column: left\n        resetPaddings: true\n        text: ''\n        image:\n          src: >-\n            https://storage.yandexcloud.net/gravity-landing-static/blog/canvas-vs-html/pic5.png\n        fullscreen: true\n      - type: blog-yfm-block\n        column: left\n        resetPaddings: true\n        text: >\n\n          **¿Y si usamos FPS para elegir el nivel de detalle?**\n\n\n          Probamos enfoques para seleccionar el nivel de detalle basándonos en FPS.\n          Pero resultó que ese enfoque crea inestabilidad: si mejora el rendimiento,\n          el sistema cambia a un modo más detallado, lo que baja los FPS y puede provocar\n          un cambio de vuelta — y así en bucle.\n      - type: blog-yfm-block\n        column: left\n        resetPaddings: true\n        text: >\n\n          ## Cómo llegamos a la solución{#solution}\n\n\n          Bien, LOD es genial. Pero su implementación requiere Canvas para el\n          rendimiento, y eso es un nuevo dolor de cabeza. Dibujar en Canvas\n          no es tan difícil — los problemas aparecen cuando hace falta\n          interactividad.\n\n\n          ### Problema: ¿cómo saber dónde hizo clic el usuario?\n\n\n          En HTML todo es simple: haces clic en un botón — recibes el evento en el elemento.\n          En Canvas es más complicado: haces clic en el lienzo — ¿y ahora qué?\n          Hay que averiguar por cuenta propia en qué elemento hizo clic el usuario.\n\n\n          Básicamente existen tres enfoques:\n\n            * Pixel Testing (color picking),\n            * Enfoque geométrico (recorrer todos los elementos),\n            * Spatial Indexing (índice espacial).\n\n          #### Pixel Testing (color picking)\n\n\n          La idea es simple: creamos un segundo canvas invisible, copiamos la escena allí,\n          pero rellenamos cada elemento con un color único que actuará como ID del objeto.\n          Al hacer clic leemos el color del píxel bajo el puntero con getImageData\n          y así obtenemos el ID del elemento.\n\n\n          #|\n\n          ||**Pros**|**Contras**||\n\n          ||* Se implementa en un par de decenas de líneas\n\n\n          * No requiere estructuras de datos adicionales|* El anti‑aliasing de Canvas mezcla colores — un clic en el borde puede dar un ID “inválido”\n\n\n          * No se puede desactivar el anti‑aliasing en 2D‑Canvas\n\n\n          * El segundo lienzo duplica la memoria y dobla el pase de render||\n\n          |#\n\n\n          Para escenas pequeñas sirve, pero con 10.000+ elementos el porcentaje\n          de errores se vuelve inaceptable — descartamos Pixel Testing.\n\n\n          #### Enfoque geométrico (recorrer todos los elementos)\n\n\n          La idea es simple: recorremos todos los elementos y comprobamos si el punto\n          del clic está dentro del elemento.\n\n\n          #|\n\n          ||**Pros**|**Contras**||\n\n          ||* Se implementa en un par de decenas de líneas\n\n\n          * No requiere estructuras de datos adicionales|* Muy lento con muchos elementos\n\n\n          * No sirve para escenas grandes||\n\n          |#\n\n\n          #### Spatial Indexing\n\n\n          Una evolución del enfoque geométrico. En el enfoque geométrico chocábamos\n          con la cantidad de elementos. Los algoritmos de índice espacial intentan\n          agrupar elementos cercanos usando principalmente árboles, lo que permite\n          reducir la complejidad a log n.\n\n\n          Hay bastantes algoritmos de índice espacial; nosotros elegimos la estructura\n          de datos R‑Tree usando la biblioteca\n          [rbush](https://github.com/mourner/rbush){target=\"_blank\"}.\n\n\n          R‑Tree es, como indica el nombre, un árbol donde cada objeto\n          se coloca en un rectángulo mínimo (MBR), y luego estos rectángulos\n          se agrupan en rectángulos más grandes. Así se obtiene un árbol\n          donde cada rectángulo contiene otros rectángulos.\n      - type: blog-media-block\n        column: left\n        resetPaddings: true\n        text: >-\n          Imagen de Wikipedia\n          [R‑tree](https://en.wikipedia.org/wiki/R-tree){target=\"_blank\"}\n        image:\n          src: >-\n            https://storage.yandexcloud.net/gravity-landing-static/blog/canvas-vs-html/pic6.png\n        fullscreen: true\n      - type: blog-yfm-block\n        column: left\n        resetPaddings: true\n        text: >\n\n          Para buscar en un RTree debemos bajar por el árbol (hacia la profundidad\n          del rectángulo) hasta llegar al elemento concreto. La ruta se elige comprobando\n          la intersección del rectángulo de búsqueda con los MBR. Todas las ramas cuyo\n          bounding‑box ni siquiera toca el rectángulo de búsqueda se descartan de inmediato —\n          por eso la profundidad de recorrido suele limitarse a 3–5 niveles, y la búsqueda\n          toma microsegundos incluso con decenas de miles de elementos.\n\n\n          Esta variante, aunque funciona más lento (O(log n) en el mejor caso y\n          O(n) en el peor) que el pixel testing, es más precisa y menos exigente\n          con la memoria.\n\n\n          #### Modelo de eventos\n\n\n          Con base en el RTree ahora podemos construir nuestro modelo de eventos.\n          Cuando el usuario hace clic, se запуска un hit‑test: formamos un\n          rectángulo de 1×1 píxel en las coordenadas del cursor y buscamos su\n          intersección en el R‑Tree. Al obtener el elemento en el que cae ese rectángulo,\n          delegamos el evento a ese elemento. Si el elemento no detuvo el evento,\n          este se pasa a su padre y así hasta la raíz. El comportamiento de este\n          modelo se parece al modelo de eventos del navegador. Los eventos se pueden\n          interceptar, prevenir o detener su burbujeo.\n\n\n          Como ya mencioné, en el hit‑test formamos un rectángulo de 1×1 píxel,\n          lo que significa que podemos formar un rectángulo de cualquier tamaño.\n          Y eso nos ayudará a hacer otra optimización muy importante — Spatial Culling.\n\n\n          ### Spatial Culling\n\n\n          Spatial Culling es una técnica de optimización del renderizado cuyo objetivo\n          es no dibujar lo que no se ve. Por ejemplo, no dibujar objetos que están fuera\n          del espacio de la cámara o que están tapados por otros elementos de la escena.\n          Como nuestro grafo se dibuja en un espacio 2D, basta con no dibujar los objetos\n          que están fuera del área visible de la cámara (viewport).\n\n\n          Cómo funciona:\n\n            * en cada desplazamiento o zoom de la cámara formamos un rectángulo igual al viewport actual;\n            * buscamos su intersección en el R‑Tree;\n            * el resultado es una lista de elementos que realmente son visibles;\n            * renderizamos solo esos, el resto se omite.\n\n          Este enfoque hace que el rendimiento sea casi independiente del número total\n          de elementos: si en el frame caben 40 bloques, la biblioteca dibujará exactamente 40,\n          y no decenas de miles ocultos fuera de la pantalla. En escalas lejanas entran muchos\n          elementos en el viewport, así que dibujamos primitivas ligeras de Canvas; al acercar\n          la cámara, la cantidad de elementos disminuye y los recursos liberados permiten\n          cambiar al modo HTML con detalle completo.\n\n\n          Uniéndolo todo, queda un esquema simple:\n\n            * Canvas se encarga de la velocidad,\n            * HTML — de la interactividad,\n            * R‑Tree y Spatial Culling los combinan silenciosamente en un sistema único, permitiendo determinar rápidamente qué elementos se pueden dibujar en la capa HTML.\n\n          Mientras la cámara se mueve, el viewport pequeño pide al R‑Tree solo\n          los objetos que realmente están en el encuadre. Este enfoque nos permite\n          dibujar grafos realmente grandes o, al menos, tener margen de rendimiento\n          hasta que el usuario limite el viewport.\n\n\n          En resumen, en su núcleo la biblioteca contiene:\n\n            * modo Canvas con primitivas simples;\n            * modo HTML con detalle completo;\n            * R‑Tree y Spatial Culling para optimización de rendimiento;\n            * un modelo de eventos familiar.\n\n          Pero para producción esto no es suficiente: hace falta poder\n          ampliar la biblioteca y personalizarla para las propias necesidades.\n      - type: blog-yfm-block\n        column: left\n        resetPaddings: true\n        text: >\n\n          ## Personalización{#customization}\n\n\n          La biblioteca ofrece dos formas complementarias de ampliar y cambiar el comportamiento:\n\n            * Redefinición de componentes base. Cambiamos la lógica de los Block, Anchor y Connection estándar.\n            * Extensión mediante capas (Layers). Añadimos funcionalidad fundamentalmente nueva por encima/debajo de la escena existente.\n\n          ### Redefinición de componentes\n\n\n          Cuando hay que modificar el aspecto o comportamiento de elementos existentes,\n          heredamos de la clase base y redefinimos los métodos clave.\n          Luego registramos el componente con nuestro propio nombre.\n\n\n          #### Personalización de bloques\n\n\n          Por ejemplo, si necesita crear un grafo con barras de progreso en los bloques —\n          digamos, para mostrar el estado de ejecución de tareas en un pipeline —\n          puede personalizar fácilmente los bloques estándar:\n\n\n          ```json\n\n          import { CanvasBlock } from \"@gravity‑ui/graph\";\n\n\n          class ProgressBlock extends CanvasBlock {\n            // Forma base del bloque con esquinas redondeadas\n            public override renderBody(ctx: CanvasRenderingContext2D): void {\n              ctx.fillStyle = \"#ddd\";\n              ctx.beginPath();\n              ctx.roundRect(this.state.x, this.state.y, this.state.width, this.state.height, 12);\n              ctx.fill();\n              ctx.closePath();\n            }\n\n            public renderSchematicView(ctx: CanvasRenderingContext2D): void {\n              const progress = this.state.meta?.progress || 0;\n\n              // Dibujamos la base del bloque\n              this.renderBody(ctx);\n\n              // Barra de progreso con indicación de color\n              const progressWidth = (this.state.width - 20) * (progress / 100);\n              ctx.fillStyle = progress < 50 ? \"#ff6b6b\" : progress < 80 ? \"#feca57\" : \"#48cae4\";\n              ctx.fillRect(this.state.x + 10, this.state.y + this.state.height - 15, progressWidth, 8);\n\n              // Marco de la barra de progreso\n              ctx.strokeStyle = \"#ddd\";\n              ctx.lineWidth = 1;\n              ctx.strokeRect(this.state.x + 10, this.state.y + this.state.height - 15, this.state.width - 20, 8);\n\n              // Texto con porcentajes y nombre\n              ctx.fillStyle = \"#2d3436\";\n              ctx.font = \"12px Arial\";\n              ctx.textAlign = \"center\";\n              ctx.fillText(`${Math.round(progress)}%`, this.state.x + this.state.width / 2, this.state.y + 20);\n              ctx.fillText(this.state.name, this.state.x + this.state.width / 2, this.state.y + 40);\n            }\n          }\n\n          ```\n\n\n          #### Personalización de conexiones\n\n\n          De forma similar, si necesita cambiar el comportamiento y el aspecto de las conexiones —\n          por ejemplo, para mostrar la intensidad del flujo de datos entre bloques —\n          puede crear una conexión personalizada:\n\n\n          ```json\n\n          import { BlockConnection } from \"@gravity-ui/graph\";\n\n\n          class DataFlowConnection extends BlockConnection {\n            public override style(ctx: CanvasRenderingContext2D) {\n              // Obtenemos datos del flujo desde los bloques conectados\n              const sourceBlock = this.sourceBlock;\n              const targetBlock = this.targetBlock;\n\n              const sourceProgress = sourceBlock?.state.meta?.progress || 0;\n              const targetProgress = targetBlock?.state.meta?.progress || 0;\n\n              // Calculamos la intensidad del flujo basándonos en el progreso de los bloques\n              const flowRate = Math.min(sourceProgress, targetProgress);\n              const isActive = flowRate > 10; // El flujo está activo si el progreso > 10%\n\n              if (isActive) {\n                // Flujo activo -- línea verde gruesa\n                ctx.strokeStyle = \"#00b894\";\n                ctx.lineWidth = Math.max(2, Math.min(6, flowRate / 20));\n              } else {\n                // Flujo inactivo -- línea gris discontinua\n                ctx.strokeStyle = \"#ddd\";\n                ctx.lineWidth = this.context.camera.getCameraScale();\n                ctx.setLineDash([5, 5]);\n              }\n\n              return { type: \"stroke\" };\n            }\n          }\n\n          ```\n\n\n          #### Uso de componentes personalizados\n\n\n          Registramos los componentes creados en la configuración del grafo:\n\n\n          ```json\n\n          const customGraph = new Graph({\n            blocks: [\n              {\n                id: \"task1\",\n                is: \"progress\",\n                x: 100,\n                y: 100,\n                width: 200,\n                height: 80,\n                name: \"Data Processing\",\n                meta: { progress: 75 },\n              },\n              {\n                id: \"task2\",\n                is: \"progress\",\n                x: 400,\n                y: 100,\n                width: 200,\n                height: 80,\n                name: \"Analysis\",\n                meta: { progress: 30 },\n              },\n              {\n                id: \"task3\",\n                is: \"progress\",\n                x: 700,\n                y: 100,\n                width: 200,\n                height: 80,\n                name: \"Output\",\n                meta: { progress: 5 },\n              },\n            ],\n            connections: [\n              { sourceBlockId: \"task1\", targetBlockId: \"task2\" },\n              { sourceBlockId: \"task2\", targetBlockId: \"task3\" },\n            ],\n            settings: {\n              // Registramos bloques personalizados\n              blockComponents: {\n                'progress': ProgressBlock,\n              },\n              // Registramos una conexión personalizada para todas las conexiones\n              connection: DataFlowConnection,\n              useBezierConnections: true,\n            },\n          });\n\n\n          customGraph.setEntities({\n            blocks: [\n              {\n              is: 'progress',\n              id: '1',\n              name: \"progress block',\n              x: 10, \n              y: 10, \n              width: 10, \n              height: 10,\n              anchors: [],\n              selected: false,\n              }\n            ]\n          })\n\n\n          customGraph.start();\n\n          ```\n\n\n          #### Resultado\n\n\n          Como resultado obtenemos un grafo donde:\n\n            * los bloques muestran el progreso actual con indicación por color;\n            * las conexiones visualizan el flujo de datos: flujos activos — verdes y gruesos, inactivos — grises y discontinuos;\n            * al hacer zoom los bloques cambian automáticamente al modo HTML con interactividad completa.\n\n          ### Extensión mediante capas\n\n\n          Las capas son elementos Canvas o HTML adicionales que se insertan en el “espacio”\n          del grafo. En esencia, cada capa es un canal de renderizado separado que puede\n          contener su propio canvas para gráficos rápidos o un contenedor HTML para\n          elementos interactivos complejos.\n\n\n          Por cierto, así es como funciona la integración con React de nuestra biblioteca:\n          los componentes React se renderizan en la capa HTML a través de React Portal.\n\n\n          #### Arquitectura de capas\n\n\n          Las capas son otra solución clave al dilema Canvas vs HTML.\n          Sincronizan las posiciones de los elementos Canvas y HTML, garantizando\n          el solapamiento correcto entre ellos. Esto permite cambiar sin fricción\n          entre Canvas y HTML permaneciendo en el mismo espacio. El grafo\n          consta de capas independientes superpuestas:\n      - type: blog-media-block\n        column: left\n        resetPaddings: true\n        text: ''\n        image:\n          src: >-\n            https://storage.yandexcloud.net/gravity-landing-static/blog/canvas-vs-html/pic7.png\n        fullscreen: true\n      - type: blog-yfm-block\n        column: left\n        resetPaddings: true\n        text: >\n\n          Las capas pueden trabajar en dos sistemas de coordenadas:\n\n            * Vinculadas al grafo (`transformByCameraPosition: true`):\n\n              * los elementos se mueven junto con la cámara,\n              * bloques, conexiones, elementos del grafo.\n\n            * Fijadas en la pantalla (`transformByCameraPosition: false`):\n\n              * se quedan en su sitio al hacer panorámica,\n              * toolbars, leyendas, controles de UI.\n\n          #### Cómo está hecha la integración con React\n\n\n          Una capa con integración React es bastante ilustrativa para mostrar qué son las capas.\n          Primero, veamos un componente que resalta la lista de bloques que están dentro\n          del área visible de la cámara. Para ello debemos suscribirnos a los cambios de cámara y,\n          tras cada cambio, comprobar la intersección del viewport de la cámara con el hitbox\n          de los elementos.\n\n\n          ```json\n\n          import { Graph } from \"@gravity-ui/graph\";\n\n\n          const BlocksList = ({ graph, renderBlock }: { graph: Graph,\n          renderBlock: (graph: Graph, block: TBlock) => React.JSX.Element }) =>\n          {\n            const [blocks, setBlocks] = useState([]);\n\n            const updateVisibleList = useCallback(() => {\n              const cameraState = graph.cameraService.getCameraState();\n              const CAMERA_VIEWPORT_TRESHOLD = 0.5;\n              const x = -cameraState.relativeX - cameraState.relativeWidth * CAMERA_VIEWPORT_TRESHOLD;\n              const y = -cameraState.relativeY - cameraState.relativeHeight * CAMERA_VIEWPORT_TRESHOLD;\n              const width = -cameraState.relativeX + cameraState.relativeWidth * (1 + CAMERA_VIEWPORT_TRESHOLD) - x;\n              const height = -cameraState.relativeY + cameraState.relativeHeight * (1 + CAMERA_VIEWPORT_TRESHOLD) - y;\n              \n              const blocks = graph\n                .getElementsOverRect(\n                  {\n                    x,\n                    y,\n                    width,\n                    height,\n                  }, // define el área en la que se buscará la lista de bloques\n                  [CanvasBlock] // define los tipos de elementos que se buscarán en el área visible de la cámara\n                ).map((component) => component.connectedState); // Obtenemos la lista de modelos de bloques\n\n                setBlocks(blocks);\n            });\n\n              useGraphEvent(graph, \"camera-change\", ({ scale }) => {\n                if (scale >= 0.7) {\n                  // Si el zoom es mayor que 0.7, actualizamos la lista de bloques\n                  updateVisibleList()\n                  return;\n                }\n                setBlocks([]);\n              });\n\n              return blocks.map(block => <React.Fragment key={block.id}>{renderBlock(graphObject, block)}</React.Fragment>)\n          }\n\n          ```\n\n\n          Ahora veamos la descripción de la propia capa que usará este componente.\n\n\n          ```json\n\n          import { Layer } from '@gravity-ui/graph';\n\n\n          class ReactLayer extends Layer {\n            constructor(props: TReactLayerProps) {\n              super({\n                html: {\n                  zIndex: 3, // elevamos la capa por encima del resto\n                  classNames: [\"no-user-select\"], // añadimos una clase para desactivar la selección de texto\n                  transformByCameraPosition: true, // la capa está vinculada a la cámara: se moverá junto con ella\n                },\n                ...props,\n              });\n            }\n\n            public renderPortal(renderBlock: <T extends TBlock>(block: T) => React.JSX.Element) {\n              if (!this.getHTML()) {\n                return null;\n              }\n\n              const htmlLayer = this.getHTML() as HTMLDivElement;\n\n              return createPortal(\n                React.createElement(BlocksList, {\n                  graph: this.context.graph,\n                  renderBlock: renderBlock,\n                }),\n                htmlLayer,\n              );\n            }\n          }\n\n          ```\n\n\n          Ahora podemos usar esta capa en nuestra aplicación.\n\n\n          ```json\n\n          import { Flex } from \"@gravity-ui/uikit\";\n\n\n          const graph = useMemo(() => new Graph());\n\n          const containerRef = useRef<HTMLDivElement>();\n\n\n          useEffect(() => {\n              if (containerRef.current) {\n                graph.attach(containerRef.current);\n              }\n\n              return () => {\n                graph.detach();\n              };\n            }, [graph, containerRef]);\n\n\n          const reactLayer = useLayer(graph, ReactLayer, {});\n\n\n          const renderBlock = useCallback((graph, block) => <Block graph={graph}\n          block={block}>{block.name}</Block>)\n\n            return (\n              <div>\n                <div style={{ position: \"absolute\", overflow: \"hidden\", width: \"100%\", height: \"100%\" }} ref={containerRef}>\n                  {graph && reactLayer && reactLayer.renderPortal(renderBlock)}\n                </div>\n              </div>\n            );\n          ```\n      - type: blog-yfm-block\n        column: left\n        resetPaddings: true\n        text: >\n\n          En general, todo es bastante simple. Nada de lo descrito arriba\n          hay que escribirlo uno mismo — ya está implementado y listo para usar.\n      - type: blog-yfm-block\n        column: left\n        resetPaddings: true\n        text: >\n\n          ## Nuestra biblioteca de grafos: ventajas y cómo usarla{#library}\n\n\n          Cuando empezamos a trabajar en la biblioteca, la pregunta principal era:\n          ¿cómo hacer que el desarrollador no tenga que elegir entre\n          rendimiento y comodidad de desarrollo? La respuesta estuvo en\n          automatizar esa elección.\n\n\n          ### Ventajas\n\n\n          #### Rendimiento + comodidad\n\n\n          [@gravity‑ui/graph](https://github.com/gravity-ui/graph){target=\"_blank\"}\n          cambia automáticamente entre Canvas y HTML según el\n          nivel de zoom. Esto significa que obtienes:\n\n            * 60 FPS estables en grafos con miles de elementos.\n            * Posibilidad de usar componentes HTML completos con interactividad rica al ver con detalle.\n            * Un modelo de eventos unificado independientemente del renderizado — click, mouseenter funcionan igual en Canvas y en HTML.\n\n          #### Compatibilidad con bibliotecas de UI\n\n\n          Una de las principales ventajas es la compatibilidad con cualquier biblioteca de UI.\n          Si tu equipo usa:\n\n            * Gravity UI,\n            * Material‑UI,\n            * Ant Design,\n            * componentes propios.\n\n          … ¡no tienes que renunciar a ellas! Al aumentar el zoom, el grafo cambia\n          automáticamente al modo HTML, donde los `Button`,\n          `Select`, `DatePicker` habituales en el tema de color que necesites\n          funcionan igual que en una aplicación React normal.\n\n\n          #### Agnóstico de framework\n\n\n          Aunque implementamos el renderer HTML base usando React,\n          intentamos desarrollar la biblioteca de forma que siga siendo\n          agnóstica de framework. Es decir, si hace falta, puedes implementar\n          con relativa facilidad una capa de integración con tu framework favorito.\n      - type: blog-yfm-block\n        column: left\n        resetPaddings: true\n        text: \"\\n## ¿Y hay alternativas?{#analogs}\\n\\nEn el mercado actualmente hay bastantes soluciones para dibujar grafos: desde soluciones de pago como [yFiles](https://yfiles.dev/){target=\\\"_blank\\\"} y [JointJS](https://github.com/clientIO/joint){target=\\\"_blank\\\"}, hasta soluciones open source como [Foblex Flow](https://github.com/Foblex/f-flow){target=\\\"_blank\\\"}, [baklavajs](https://github.com/newcat/baklavajs){target=\\\"_blank\\\"} y [jsPlumb](https://github.com/jsplumb/community-edition){target=\\\"_blank\\\"}. Pero para comparar consideramos [@antv/g6](https://github.com/antvis/G6){target=\\\"_blank\\\"} y [React Flow](https://github.com/xyflow/xyflow){target=\\\"_blank\\\"} como las herramientas más populares. Cada una tiene sus particularidades.\\n\\nReact Flow es una buena biblioteca enfocada en construir interfaces node‑based. Tiene muchas capacidades, pero debido a que usa SVG y HTML, el rendimiento es bastante modesto. La biblioteca es buena cuando estás seguro de que los grafos no superarán 100–200 bloques.\\n\\nPor su parte, @antv/g6 tiene un montón de funcionalidades; soporta Canvas y, en particular, WebGL. Probablemente no se puede comparar directamente @antv/g6 con @gravity‑ui/graph: el equipo está más orientado a grafos y diagramas, aunque también soporta UI node‑based. Así que antv/g6 encaja si te importa no solo la interfaz node‑based, sino también dibujar gráficas/diagramas.\\n\\nAunque @antv/g6 sabe tanto canvas/webgl como html/svg, las reglas de conmutación tendrás que gestionarlas a mano, y hay que hacerlo bien. En rendimiento es mucho más rápida que React Flow, pero aún así surgen dudas. Aunque se declara soporte de WebGL, si miras su [stress test](https://g6.antv.antgroup.com/en/examples/performance/massive-data#60000){target=\\\"_blank\\\"}, se nota que con 60k nodos la biblioteca no puede ofrecer dinamismo — en un MacBook M3 el renderizado de un frame tardó 4 segundos. Para comparar: nuestro [stress test](https://preview.gravity-ui.com/graph/?path=/story/stories-main-grapheditor--graph-stress-test){target=\\\"_blank\\\"} con 111k nodos y 109k conexiones en el mismo Macbook M3: renderizar la escena completa del grafo toma ~60ms, lo que da ~15–20 FPS. No es mucho, pero gracias a Spatial Culling se puede limitar el viewport y así mejorar la capacidad de respuesta. Aunque los maintainers [declararon](https://github.com/antvis/G6/issues/1597){target=\\\"_blank\\\"} que quieren lograr renderizar 100k nodos a 30 FPS, por lo visto aún no lo han conseguido.\\n\\nOtro punto en el que @gravity‑ui/graph gana es el tamaño del bundle.\\n\\n#|\\n|||Bundle size Minified|Bundle size Minified + Gzipped||\\n||@antv/g6 [bundlephobia](https://bundlephobia.com/package/@antv/g6@5.0.49){target=\\\"_blank\\\"}|1.1 MB|324.5\\_kB||\\n||react flow [bundlephobia](https://bundlephobia.com/package/@xyflow/react@12.8.1){target=\\\"_blank\\\"}|181.2\\_kB|56.4\\_kB||\\n||@gravity-ui/graph [bundlephobia](https://bundlephobia.com/package/@gravity-ui/graph){target=\\\"_blank\\\"}|2.2\\_kB|672\\_B||\\n|#\\n\\nAunque ambas bibliotecas son bastante potentes en rendimiento o en facilidad de integración, @gravity‑ui/graph tiene varias ventajas: puede ofrecer rendimiento en grafos realmente grandes, mantener UI/UX para el usuario y simplificar el desarrollo.\\n\"\n      - type: blog-yfm-block\n        column: left\n        resetPaddings: true\n        text: >\n\n          ## Planes para el futuro{#future}\n\n\n          Ya ahora la biblioteca tiene suficiente margen de rendimiento\n          para la mayoría de tareas, así que en el futuro cercano prestaremos\n          más atención al desarrollo del ecosistema alrededor de la biblioteca:\n          desarrollaremos capas (plugins), integraciones para otras bibliotecas\n          y frameworks (Angular/Vue/Svelte, …etc), añadiremos soporte para\n          dispositivos táctiles, adaptación para navegadores móviles y, en general,\n          mejoraremos UX/DX.\n      - type: blog-yfm-block\n        column: left\n        resetPaddings: true\n        text: >\n\n          ## Pruébalo y únete{#try}\n\n\n          En el [repositorio](https://github.com/gravity-ui/graph){target=\"_blank\"}\n          encontrarás una biblioteca totalmente funcional:\n\n            * Núcleo en Canvas + R‑Tree (≈ 30K líneas de código),\n            * Integración con React,\n            * Storybook con ejemplos.\n\n          Puedes instalar la biblioteca en una sola línea:\n\n\n          `npm install @gravity-ui/graph`\n\n\n          --------------\n\n\n          Durante bastante tiempo, la biblioteca que hoy se llama @gravity‑ui/graph\n          fue una herramienta interna dentro de Nirvana, y el enfoque elegido\n          se probó muy bien en la práctica. Ahora queremos compartir nuestro trabajo\n          y ayudar a desarrolladores externos a dibujar sus grafos de forma\n          más simple, rápida y eficiente.\n\n\n          Queremos estandarizar los enfoques para mostrar grafos complejos en\n          la comunidad open source: demasiados equipos reinventan la rueda\n          o sufren con herramientas inadecuadas.\n\n\n          Por eso es muy importante para nosotros reunir tu feedback:\n          distintos proyectos traen distintos edge cases que permiten\n          mejorar la biblioteca. Esto nos ayudará a pulirla y a hacer crecer\n          más rápido el ecosistema de Gravity UI.\n  - type: blog-layout-block\n    resetPaddings: true\n    fullWidth: false\n    children:\n      - type: blog-meta-block\n        column: left\n        resetPaddings: true\n  - type: blog-suggest-block\n    resetPaddings: true\n",
    "title": "",
    "noIndex": false,
    "shareTitle": null,
    "shareDescription": null,
    "shareImage": "https://storage.yandexcloud.net/gravity-landing-static/blog/blog-cover-bg.png",
    "pageLocaleId": null,
    "author": "timofeyevvv",
    "metaDescription": null,
    "keywords": [],
    "shareGenTitle": null,
    "canonicalLink": null,
    "sharingType": "semi-full",
    "sharingTheme": "dark",
    "comment": "sharing pic",
    "shareImageUrl": "https://storage.cloud-preprod.yandex.net/ui-api-ru-preprod-stable-share-generator-screenshots/cache/b155df2ab692d6e154ff809a7d91b9ad4789de53.png",
    "pageRegionId": 76,
    "summary": null,
    "versionId": 216,
    "service": null,
    "solution": null,
    "locales": [
      {
        "id": 75,
        "pageId": 71,
        "locale": "ru",
        "createdAt": "2026-01-15T11:26:48.440Z",
        "updatedAt": "2026-01-15T11:26:48.519Z",
        "publishedVersionId": null,
        "lastVersionId": 195
      },
      {
        "id": 76,
        "pageId": 71,
        "locale": "en",
        "createdAt": "2026-01-15T11:26:48.532Z",
        "updatedAt": "2026-01-15T11:26:48.609Z",
        "publishedVersionId": null,
        "lastVersionId": 196
      }
    ],
    "pageRegions": [
      {
        "regionCode": "ru-ru",
        "publishedVersionId": 199
      },
      {
        "regionCode": "en",
        "publishedVersionId": 216
      }
    ],
    "searchCategory": {
      "id": 7,
      "slug": "blog",
      "title": "Blog",
      "url": "/blog"
    },
    "voiceovers": []
  }
  